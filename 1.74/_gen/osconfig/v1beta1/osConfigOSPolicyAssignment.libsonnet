{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='osConfigOSPolicyAssignment', url='', help=''),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of OSConfigOSPolicyAssignment', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'osconfig.cnrm.cloud.google.com/v1beta1',
    kind: 'OSConfigOSPolicyAssignment',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help=''),
  spec: {
    '#instanceFilter':: d.obj(help='"Required. Filter to select VMs."'),
    instanceFilter: {
      '#exclusionLabels':: d.obj(help='"List of label sets used for VM exclusion. If the list has more than one label set, the VM is excluded if any of the label sets are applicable for the VM."'),
      exclusionLabels: {
        '#withLabels':: d.fn(help='"Labels are identified by key/value pairs in this map. A VM should contain all the key/value pairs specified in this map to be selected."', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { labels: labels },
        '#withLabelsMixin':: d.fn(help='"Labels are identified by key/value pairs in this map. A VM should contain all the key/value pairs specified in this map to be selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { labels+: labels },
      },
      '#inclusionLabels':: d.obj(help='"List of label sets used for VM inclusion. If the list has more than one `LabelSet`, the VM is included if any of the label sets are applicable for the VM."'),
      inclusionLabels: {
        '#withLabels':: d.fn(help='"Labels are identified by key/value pairs in this map. A VM should contain all the key/value pairs specified in this map to be selected."', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { labels: labels },
        '#withLabelsMixin':: d.fn(help='"Labels are identified by key/value pairs in this map. A VM should contain all the key/value pairs specified in this map to be selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { labels+: labels },
      },
      '#inventories':: d.obj(help='"List of inventories to select VMs. A VM is selected if its inventory data matches at least one of the following inventories."'),
      inventories: {
        '#withOsShortName':: d.fn(help='"Required. The OS short name"', args=[d.arg(name='osShortName', type=d.T.string)]),
        withOsShortName(osShortName): { osShortName: osShortName },
        '#withOsVersion':: d.fn(help='"The OS version Prefix matches are supported if asterisk(*) is provided as the last character. For example, to match all versions with a major version of `7`, specify the following value for this field `7.*` An empty string matches all OS versions."', args=[d.arg(name='osVersion', type=d.T.string)]),
        withOsVersion(osVersion): { osVersion: osVersion },
      },
      '#withAll':: d.fn(help='"Target all VMs in the project. If true, no other criteria is permitted."', args=[d.arg(name='all', type=d.T.boolean)]),
      withAll(all): { spec+: { instanceFilter+: { all: all } } },
      '#withExclusionLabels':: d.fn(help='"List of label sets used for VM exclusion. If the list has more than one label set, the VM is excluded if any of the label sets are applicable for the VM."', args=[d.arg(name='exclusionLabels', type=d.T.array)]),
      withExclusionLabels(exclusionLabels): { spec+: { instanceFilter+: { exclusionLabels: if std.isArray(v=exclusionLabels) then exclusionLabels else [exclusionLabels] } } },
      '#withExclusionLabelsMixin':: d.fn(help='"List of label sets used for VM exclusion. If the list has more than one label set, the VM is excluded if any of the label sets are applicable for the VM."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='exclusionLabels', type=d.T.array)]),
      withExclusionLabelsMixin(exclusionLabels): { spec+: { instanceFilter+: { exclusionLabels+: if std.isArray(v=exclusionLabels) then exclusionLabels else [exclusionLabels] } } },
      '#withInclusionLabels':: d.fn(help='"List of label sets used for VM inclusion. If the list has more than one `LabelSet`, the VM is included if any of the label sets are applicable for the VM."', args=[d.arg(name='inclusionLabels', type=d.T.array)]),
      withInclusionLabels(inclusionLabels): { spec+: { instanceFilter+: { inclusionLabels: if std.isArray(v=inclusionLabels) then inclusionLabels else [inclusionLabels] } } },
      '#withInclusionLabelsMixin':: d.fn(help='"List of label sets used for VM inclusion. If the list has more than one `LabelSet`, the VM is included if any of the label sets are applicable for the VM."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='inclusionLabels', type=d.T.array)]),
      withInclusionLabelsMixin(inclusionLabels): { spec+: { instanceFilter+: { inclusionLabels+: if std.isArray(v=inclusionLabels) then inclusionLabels else [inclusionLabels] } } },
      '#withInventories':: d.fn(help='"List of inventories to select VMs. A VM is selected if its inventory data matches at least one of the following inventories."', args=[d.arg(name='inventories', type=d.T.array)]),
      withInventories(inventories): { spec+: { instanceFilter+: { inventories: if std.isArray(v=inventories) then inventories else [inventories] } } },
      '#withInventoriesMixin':: d.fn(help='"List of inventories to select VMs. A VM is selected if its inventory data matches at least one of the following inventories."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='inventories', type=d.T.array)]),
      withInventoriesMixin(inventories): { spec+: { instanceFilter+: { inventories+: if std.isArray(v=inventories) then inventories else [inventories] } } },
    },
    '#osPolicies':: d.obj(help='"Required. List of OS policies to be applied to the VMs."'),
    osPolicies: {
      '#resourceGroups':: d.obj(help='"Required. List of resource groups for the policy. For a particular VM, resource groups are evaluated in the order specified and the first resource group that is applicable is selected and the rest are ignored. If none of the resource groups are applicable for a VM, the VM is considered to be non-compliant w.r.t this policy. This behavior can be toggled by the flag `allow_no_resource_group_match`"'),
      resourceGroups: {
        '#inventoryFilters':: d.obj(help="\"List of inventory filters for the resource group. The resources in this resource group are applied to the target VM if it satisfies at least one of the following inventory filters. For example, to apply this resource group to VMs running either `RHEL` or `CentOS` operating systems, specify 2 items for the list with following values: inventory_filters[0].os_short_name='rhel' and inventory_filters[1].os_short_name='centos' If the list is empty, this resource group will be applied to the target VM unconditionally.\""),
        inventoryFilters: {
          '#withOsShortName':: d.fn(help='"Required. The OS short name"', args=[d.arg(name='osShortName', type=d.T.string)]),
          withOsShortName(osShortName): { osShortName: osShortName },
          '#withOsVersion':: d.fn(help='"The OS version Prefix matches are supported if asterisk(*) is provided as the last character. For example, to match all versions with a major version of `7`, specify the following value for this field `7.*` An empty string matches all OS versions."', args=[d.arg(name='osVersion', type=d.T.string)]),
          withOsVersion(osVersion): { osVersion: osVersion },
        },
        '#resources':: d.obj(help='"Required. List of resources configured for this resource group. The resources are executed in the exact order specified here."'),
        resources: {
          '#exec':: d.obj(help='"Exec resource"'),
          exec: {
            '#enforce':: d.obj(help='"What to run to bring this resource into the desired state. An exit code of 100 indicates \\"success\\", any other exit code indicates a failure running enforce."'),
            enforce: {
              '#file':: d.obj(help='"A remote or local file."'),
              file: {
                '#gcs':: d.obj(help='"A Cloud Storage object."'),
                gcs: {
                  '#withBucket':: d.fn(help='"Required. Bucket of the Cloud Storage object."', args=[d.arg(name='bucket', type=d.T.string)]),
                  withBucket(bucket): { exec+: { enforce+: { file+: { gcs+: { bucket: bucket } } } } },
                  '#withGeneration':: d.fn(help='"Generation number of the Cloud Storage object."', args=[d.arg(name='generation', type=d.T.integer)]),
                  withGeneration(generation): { exec+: { enforce+: { file+: { gcs+: { generation: generation } } } } },
                  '#withObject':: d.fn(help='"Required. Name of the Cloud Storage object."', args=[d.arg(name='object', type=d.T.string)]),
                  withObject(object): { exec+: { enforce+: { file+: { gcs+: { object: object } } } } },
                },
                '#remote':: d.obj(help='"A generic remote file."'),
                remote: {
                  '#withSha256Checksum':: d.fn(help='"SHA256 checksum of the remote file."', args=[d.arg(name='sha256Checksum', type=d.T.string)]),
                  withSha256Checksum(sha256Checksum): { exec+: { enforce+: { file+: { remote+: { sha256Checksum: sha256Checksum } } } } },
                  '#withUri':: d.fn(help='"Required. URI from which to fetch the object. It should contain both the protocol and path following the format `{protocol}://{location}`."', args=[d.arg(name='uri', type=d.T.string)]),
                  withUri(uri): { exec+: { enforce+: { file+: { remote+: { uri: uri } } } } },
                },
                '#withAllowInsecure':: d.fn(help='"Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified."', args=[d.arg(name='allowInsecure', type=d.T.boolean)]),
                withAllowInsecure(allowInsecure): { exec+: { enforce+: { file+: { allowInsecure: allowInsecure } } } },
                '#withLocalPath':: d.fn(help='"A local path within the VM to use."', args=[d.arg(name='localPath', type=d.T.string)]),
                withLocalPath(localPath): { exec+: { enforce+: { file+: { localPath: localPath } } } },
              },
              '#withArgs':: d.fn(help='"Optional arguments to pass to the source during execution."', args=[d.arg(name='args', type=d.T.array)]),
              withArgs(args): { exec+: { enforce+: { args: if std.isArray(v=args) then args else [args] } } },
              '#withArgsMixin':: d.fn(help='"Optional arguments to pass to the source during execution."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='args', type=d.T.array)]),
              withArgsMixin(args): { exec+: { enforce+: { args+: if std.isArray(v=args) then args else [args] } } },
              '#withInterpreter':: d.fn(help='"Required. The script interpreter to use. Possible values: INTERPRETER_UNSPECIFIED, NONE, SHELL, POWERSHELL"', args=[d.arg(name='interpreter', type=d.T.string)]),
              withInterpreter(interpreter): { exec+: { enforce+: { interpreter: interpreter } } },
              '#withOutputFilePath':: d.fn(help='"Only recorded for enforce Exec. Path to an output file (that is created by this Exec) whose content will be recorded in OSPolicyResourceCompliance after a successful run. Absence or failure to read this file will result in this ExecResource being non-compliant. Output file size is limited to 100K bytes."', args=[d.arg(name='outputFilePath', type=d.T.string)]),
              withOutputFilePath(outputFilePath): { exec+: { enforce+: { outputFilePath: outputFilePath } } },
              '#withScript':: d.fn(help='"An inline script. The size of the script is limited to 1024 characters."', args=[d.arg(name='script', type=d.T.string)]),
              withScript(script): { exec+: { enforce+: { script: script } } },
            },
            '#validate':: d.obj(help='"Required. What to run to validate this resource is in the desired state. An exit code of 100 indicates \\"in desired state\\", and exit code of 101 indicates \\"not in desired state\\". Any other exit code indicates a failure running validate."'),
            validate: {
              '#file':: d.obj(help='"A remote or local file."'),
              file: {
                '#gcs':: d.obj(help='"A Cloud Storage object."'),
                gcs: {
                  '#withBucket':: d.fn(help='"Required. Bucket of the Cloud Storage object."', args=[d.arg(name='bucket', type=d.T.string)]),
                  withBucket(bucket): { exec+: { validate+: { file+: { gcs+: { bucket: bucket } } } } },
                  '#withGeneration':: d.fn(help='"Generation number of the Cloud Storage object."', args=[d.arg(name='generation', type=d.T.integer)]),
                  withGeneration(generation): { exec+: { validate+: { file+: { gcs+: { generation: generation } } } } },
                  '#withObject':: d.fn(help='"Required. Name of the Cloud Storage object."', args=[d.arg(name='object', type=d.T.string)]),
                  withObject(object): { exec+: { validate+: { file+: { gcs+: { object: object } } } } },
                },
                '#remote':: d.obj(help='"A generic remote file."'),
                remote: {
                  '#withSha256Checksum':: d.fn(help='"SHA256 checksum of the remote file."', args=[d.arg(name='sha256Checksum', type=d.T.string)]),
                  withSha256Checksum(sha256Checksum): { exec+: { validate+: { file+: { remote+: { sha256Checksum: sha256Checksum } } } } },
                  '#withUri':: d.fn(help='"Required. URI from which to fetch the object. It should contain both the protocol and path following the format `{protocol}://{location}`."', args=[d.arg(name='uri', type=d.T.string)]),
                  withUri(uri): { exec+: { validate+: { file+: { remote+: { uri: uri } } } } },
                },
                '#withAllowInsecure':: d.fn(help='"Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified."', args=[d.arg(name='allowInsecure', type=d.T.boolean)]),
                withAllowInsecure(allowInsecure): { exec+: { validate+: { file+: { allowInsecure: allowInsecure } } } },
                '#withLocalPath':: d.fn(help='"A local path within the VM to use."', args=[d.arg(name='localPath', type=d.T.string)]),
                withLocalPath(localPath): { exec+: { validate+: { file+: { localPath: localPath } } } },
              },
              '#withArgs':: d.fn(help='"Optional arguments to pass to the source during execution."', args=[d.arg(name='args', type=d.T.array)]),
              withArgs(args): { exec+: { validate+: { args: if std.isArray(v=args) then args else [args] } } },
              '#withArgsMixin':: d.fn(help='"Optional arguments to pass to the source during execution."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='args', type=d.T.array)]),
              withArgsMixin(args): { exec+: { validate+: { args+: if std.isArray(v=args) then args else [args] } } },
              '#withInterpreter':: d.fn(help='"Required. The script interpreter to use. Possible values: INTERPRETER_UNSPECIFIED, NONE, SHELL, POWERSHELL"', args=[d.arg(name='interpreter', type=d.T.string)]),
              withInterpreter(interpreter): { exec+: { validate+: { interpreter: interpreter } } },
              '#withOutputFilePath':: d.fn(help='"Only recorded for enforce Exec. Path to an output file (that is created by this Exec) whose content will be recorded in OSPolicyResourceCompliance after a successful run. Absence or failure to read this file will result in this ExecResource being non-compliant. Output file size is limited to 100K bytes."', args=[d.arg(name='outputFilePath', type=d.T.string)]),
              withOutputFilePath(outputFilePath): { exec+: { validate+: { outputFilePath: outputFilePath } } },
              '#withScript':: d.fn(help='"An inline script. The size of the script is limited to 1024 characters."', args=[d.arg(name='script', type=d.T.string)]),
              withScript(script): { exec+: { validate+: { script: script } } },
            },
          },
          '#file':: d.obj(help='"File resource"'),
          file: {
            '#file':: d.obj(help='"A remote or local source."'),
            file: {
              '#gcs':: d.obj(help='"A Cloud Storage object."'),
              gcs: {
                '#withBucket':: d.fn(help='"Required. Bucket of the Cloud Storage object."', args=[d.arg(name='bucket', type=d.T.string)]),
                withBucket(bucket): { file+: { file+: { gcs+: { bucket: bucket } } } },
                '#withGeneration':: d.fn(help='"Generation number of the Cloud Storage object."', args=[d.arg(name='generation', type=d.T.integer)]),
                withGeneration(generation): { file+: { file+: { gcs+: { generation: generation } } } },
                '#withObject':: d.fn(help='"Required. Name of the Cloud Storage object."', args=[d.arg(name='object', type=d.T.string)]),
                withObject(object): { file+: { file+: { gcs+: { object: object } } } },
              },
              '#remote':: d.obj(help='"A generic remote file."'),
              remote: {
                '#withSha256Checksum':: d.fn(help='"SHA256 checksum of the remote file."', args=[d.arg(name='sha256Checksum', type=d.T.string)]),
                withSha256Checksum(sha256Checksum): { file+: { file+: { remote+: { sha256Checksum: sha256Checksum } } } },
                '#withUri':: d.fn(help='"Required. URI from which to fetch the object. It should contain both the protocol and path following the format `{protocol}://{location}`."', args=[d.arg(name='uri', type=d.T.string)]),
                withUri(uri): { file+: { file+: { remote+: { uri: uri } } } },
              },
              '#withAllowInsecure':: d.fn(help='"Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified."', args=[d.arg(name='allowInsecure', type=d.T.boolean)]),
              withAllowInsecure(allowInsecure): { file+: { file+: { allowInsecure: allowInsecure } } },
              '#withLocalPath':: d.fn(help='"A local path within the VM to use."', args=[d.arg(name='localPath', type=d.T.string)]),
              withLocalPath(localPath): { file+: { file+: { localPath: localPath } } },
            },
            '#withContent':: d.fn(help='"A a file with this content. The size of the content is limited to 1024 characters."', args=[d.arg(name='content', type=d.T.string)]),
            withContent(content): { file+: { content: content } },
            '#withPath':: d.fn(help='"Required. The absolute path of the file within the VM."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { file+: { path: path } },
            '#withPermissions':: d.fn(help='"Consists of three octal digits which represent, in order, the permissions of the owner, group, and other users for the file (similarly to the numeric mode used in the linux chmod utility). Each digit represents a three bit number with the 4 bit corresponding to the read permissions, the 2 bit corresponds to the write bit, and the one bit corresponds to the execute permission. Default behavior is 755. Below are some examples of permissions and their associated values: read, write, and execute: 7 read and execute: 5 read and write: 6 read only: 4"', args=[d.arg(name='permissions', type=d.T.string)]),
            withPermissions(permissions): { file+: { permissions: permissions } },
            '#withState':: d.fn(help='"Required. Desired state of the file. Possible values: OS_POLICY_COMPLIANCE_STATE_UNSPECIFIED, COMPLIANT, NON_COMPLIANT, UNKNOWN, NO_OS_POLICIES_APPLICABLE"', args=[d.arg(name='state', type=d.T.string)]),
            withState(state): { file+: { state: state } },
          },
          '#pkg':: d.obj(help='"Package resource"'),
          pkg: {
            '#apt':: d.obj(help='"A package managed by Apt."'),
            apt: {
              '#withName':: d.fn(help='"Required. Package name."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { pkg+: { apt+: { name: name } } },
            },
            '#deb':: d.obj(help='"A deb package file."'),
            deb: {
              '#source':: d.obj(help='"Required. A deb package."'),
              source: {
                '#gcs':: d.obj(help='"A Cloud Storage object."'),
                gcs: {
                  '#withBucket':: d.fn(help='"Required. Bucket of the Cloud Storage object."', args=[d.arg(name='bucket', type=d.T.string)]),
                  withBucket(bucket): { pkg+: { deb+: { source+: { gcs+: { bucket: bucket } } } } },
                  '#withGeneration':: d.fn(help='"Generation number of the Cloud Storage object."', args=[d.arg(name='generation', type=d.T.integer)]),
                  withGeneration(generation): { pkg+: { deb+: { source+: { gcs+: { generation: generation } } } } },
                  '#withObject':: d.fn(help='"Required. Name of the Cloud Storage object."', args=[d.arg(name='object', type=d.T.string)]),
                  withObject(object): { pkg+: { deb+: { source+: { gcs+: { object: object } } } } },
                },
                '#remote':: d.obj(help='"A generic remote file."'),
                remote: {
                  '#withSha256Checksum':: d.fn(help='"SHA256 checksum of the remote file."', args=[d.arg(name='sha256Checksum', type=d.T.string)]),
                  withSha256Checksum(sha256Checksum): { pkg+: { deb+: { source+: { remote+: { sha256Checksum: sha256Checksum } } } } },
                  '#withUri':: d.fn(help='"Required. URI from which to fetch the object. It should contain both the protocol and path following the format `{protocol}://{location}`."', args=[d.arg(name='uri', type=d.T.string)]),
                  withUri(uri): { pkg+: { deb+: { source+: { remote+: { uri: uri } } } } },
                },
                '#withAllowInsecure':: d.fn(help='"Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified."', args=[d.arg(name='allowInsecure', type=d.T.boolean)]),
                withAllowInsecure(allowInsecure): { pkg+: { deb+: { source+: { allowInsecure: allowInsecure } } } },
                '#withLocalPath':: d.fn(help='"A local path within the VM to use."', args=[d.arg(name='localPath', type=d.T.string)]),
                withLocalPath(localPath): { pkg+: { deb+: { source+: { localPath: localPath } } } },
              },
              '#withPullDeps':: d.fn(help='"Whether dependencies should also be installed. - install when false: `dpkg -i package` - install when true: `apt-get update && apt-get -y install package.deb`"', args=[d.arg(name='pullDeps', type=d.T.boolean)]),
              withPullDeps(pullDeps): { pkg+: { deb+: { pullDeps: pullDeps } } },
            },
            '#googet':: d.obj(help='"A package managed by GooGet."'),
            googet: {
              '#withName':: d.fn(help='"Required. Package name."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { pkg+: { googet+: { name: name } } },
            },
            '#msi':: d.obj(help='"An MSI package."'),
            msi: {
              '#source':: d.obj(help='"Required. The MSI package."'),
              source: {
                '#gcs':: d.obj(help='"A Cloud Storage object."'),
                gcs: {
                  '#withBucket':: d.fn(help='"Required. Bucket of the Cloud Storage object."', args=[d.arg(name='bucket', type=d.T.string)]),
                  withBucket(bucket): { pkg+: { msi+: { source+: { gcs+: { bucket: bucket } } } } },
                  '#withGeneration':: d.fn(help='"Generation number of the Cloud Storage object."', args=[d.arg(name='generation', type=d.T.integer)]),
                  withGeneration(generation): { pkg+: { msi+: { source+: { gcs+: { generation: generation } } } } },
                  '#withObject':: d.fn(help='"Required. Name of the Cloud Storage object."', args=[d.arg(name='object', type=d.T.string)]),
                  withObject(object): { pkg+: { msi+: { source+: { gcs+: { object: object } } } } },
                },
                '#remote':: d.obj(help='"A generic remote file."'),
                remote: {
                  '#withSha256Checksum':: d.fn(help='"SHA256 checksum of the remote file."', args=[d.arg(name='sha256Checksum', type=d.T.string)]),
                  withSha256Checksum(sha256Checksum): { pkg+: { msi+: { source+: { remote+: { sha256Checksum: sha256Checksum } } } } },
                  '#withUri':: d.fn(help='"Required. URI from which to fetch the object. It should contain both the protocol and path following the format `{protocol}://{location}`."', args=[d.arg(name='uri', type=d.T.string)]),
                  withUri(uri): { pkg+: { msi+: { source+: { remote+: { uri: uri } } } } },
                },
                '#withAllowInsecure':: d.fn(help='"Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified."', args=[d.arg(name='allowInsecure', type=d.T.boolean)]),
                withAllowInsecure(allowInsecure): { pkg+: { msi+: { source+: { allowInsecure: allowInsecure } } } },
                '#withLocalPath':: d.fn(help='"A local path within the VM to use."', args=[d.arg(name='localPath', type=d.T.string)]),
                withLocalPath(localPath): { pkg+: { msi+: { source+: { localPath: localPath } } } },
              },
              '#withProperties':: d.fn(help='"Additional properties to use during installation. This should be in the format of Property=Setting. Appended to the defaults of `ACTION=INSTALL REBOOT=ReallySuppress`."', args=[d.arg(name='properties', type=d.T.array)]),
              withProperties(properties): { pkg+: { msi+: { properties: if std.isArray(v=properties) then properties else [properties] } } },
              '#withPropertiesMixin':: d.fn(help='"Additional properties to use during installation. This should be in the format of Property=Setting. Appended to the defaults of `ACTION=INSTALL REBOOT=ReallySuppress`."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='properties', type=d.T.array)]),
              withPropertiesMixin(properties): { pkg+: { msi+: { properties+: if std.isArray(v=properties) then properties else [properties] } } },
            },
            '#rpm':: d.obj(help='"An rpm package file."'),
            rpm: {
              '#source':: d.obj(help='"Required. An rpm package."'),
              source: {
                '#gcs':: d.obj(help='"A Cloud Storage object."'),
                gcs: {
                  '#withBucket':: d.fn(help='"Required. Bucket of the Cloud Storage object."', args=[d.arg(name='bucket', type=d.T.string)]),
                  withBucket(bucket): { pkg+: { rpm+: { source+: { gcs+: { bucket: bucket } } } } },
                  '#withGeneration':: d.fn(help='"Generation number of the Cloud Storage object."', args=[d.arg(name='generation', type=d.T.integer)]),
                  withGeneration(generation): { pkg+: { rpm+: { source+: { gcs+: { generation: generation } } } } },
                  '#withObject':: d.fn(help='"Required. Name of the Cloud Storage object."', args=[d.arg(name='object', type=d.T.string)]),
                  withObject(object): { pkg+: { rpm+: { source+: { gcs+: { object: object } } } } },
                },
                '#remote':: d.obj(help='"A generic remote file."'),
                remote: {
                  '#withSha256Checksum':: d.fn(help='"SHA256 checksum of the remote file."', args=[d.arg(name='sha256Checksum', type=d.T.string)]),
                  withSha256Checksum(sha256Checksum): { pkg+: { rpm+: { source+: { remote+: { sha256Checksum: sha256Checksum } } } } },
                  '#withUri':: d.fn(help='"Required. URI from which to fetch the object. It should contain both the protocol and path following the format `{protocol}://{location}`."', args=[d.arg(name='uri', type=d.T.string)]),
                  withUri(uri): { pkg+: { rpm+: { source+: { remote+: { uri: uri } } } } },
                },
                '#withAllowInsecure':: d.fn(help='"Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified."', args=[d.arg(name='allowInsecure', type=d.T.boolean)]),
                withAllowInsecure(allowInsecure): { pkg+: { rpm+: { source+: { allowInsecure: allowInsecure } } } },
                '#withLocalPath':: d.fn(help='"A local path within the VM to use."', args=[d.arg(name='localPath', type=d.T.string)]),
                withLocalPath(localPath): { pkg+: { rpm+: { source+: { localPath: localPath } } } },
              },
              '#withPullDeps':: d.fn(help='"Whether dependencies should also be installed. - install when false: `rpm --upgrade --replacepkgs package.rpm` - install when true: `yum -y install package.rpm` or `zypper -y install package.rpm`"', args=[d.arg(name='pullDeps', type=d.T.boolean)]),
              withPullDeps(pullDeps): { pkg+: { rpm+: { pullDeps: pullDeps } } },
            },
            '#withDesiredState':: d.fn(help='"Required. The desired state the agent should maintain for this package. Possible values: DESIRED_STATE_UNSPECIFIED, INSTALLED, REMOVED"', args=[d.arg(name='desiredState', type=d.T.string)]),
            withDesiredState(desiredState): { pkg+: { desiredState: desiredState } },
            '#yum':: d.obj(help='"A package managed by YUM."'),
            yum: {
              '#withName':: d.fn(help='"Required. Package name."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { pkg+: { yum+: { name: name } } },
            },
            '#zypper':: d.obj(help='"A package managed by Zypper."'),
            zypper: {
              '#withName':: d.fn(help='"Required. Package name."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { pkg+: { zypper+: { name: name } } },
            },
          },
          '#repository':: d.obj(help='"Package repository resource"'),
          repository: {
            '#apt':: d.obj(help='"An Apt Repository."'),
            apt: {
              '#withArchiveType':: d.fn(help='"Required. Type of archive files in this repository. Possible values: ARCHIVE_TYPE_UNSPECIFIED, DEB, DEB_SRC"', args=[d.arg(name='archiveType', type=d.T.string)]),
              withArchiveType(archiveType): { repository+: { apt+: { archiveType: archiveType } } },
              '#withComponents':: d.fn(help='"Required. List of components for this repository. Must contain at least one item."', args=[d.arg(name='components', type=d.T.array)]),
              withComponents(components): { repository+: { apt+: { components: if std.isArray(v=components) then components else [components] } } },
              '#withComponentsMixin':: d.fn(help='"Required. List of components for this repository. Must contain at least one item."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='components', type=d.T.array)]),
              withComponentsMixin(components): { repository+: { apt+: { components+: if std.isArray(v=components) then components else [components] } } },
              '#withDistribution':: d.fn(help='"Required. Distribution of this repository."', args=[d.arg(name='distribution', type=d.T.string)]),
              withDistribution(distribution): { repository+: { apt+: { distribution: distribution } } },
              '#withGpgKey':: d.fn(help='"URI of the key file for this repository. The agent maintains a keyring at `/etc/apt/trusted.gpg.d/osconfig_agent_managed.gpg`."', args=[d.arg(name='gpgKey', type=d.T.string)]),
              withGpgKey(gpgKey): { repository+: { apt+: { gpgKey: gpgKey } } },
              '#withUri':: d.fn(help='"Required. URI for this repository."', args=[d.arg(name='uri', type=d.T.string)]),
              withUri(uri): { repository+: { apt+: { uri: uri } } },
            },
            '#goo':: d.obj(help='"A Goo Repository."'),
            goo: {
              '#withName':: d.fn(help='"Required. The name of the repository."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { repository+: { goo+: { name: name } } },
              '#withUrl':: d.fn(help='"Required. The url of the repository."', args=[d.arg(name='url', type=d.T.string)]),
              withUrl(url): { repository+: { goo+: { url: url } } },
            },
            '#yum':: d.obj(help='"A Yum Repository."'),
            yum: {
              '#withBaseUrl':: d.fn(help='"Required. The location of the repository directory."', args=[d.arg(name='baseUrl', type=d.T.string)]),
              withBaseUrl(baseUrl): { repository+: { yum+: { baseUrl: baseUrl } } },
              '#withDisplayName':: d.fn(help='"The display name of the repository."', args=[d.arg(name='displayName', type=d.T.string)]),
              withDisplayName(displayName): { repository+: { yum+: { displayName: displayName } } },
              '#withGpgKeys':: d.fn(help='"URIs of GPG keys."', args=[d.arg(name='gpgKeys', type=d.T.array)]),
              withGpgKeys(gpgKeys): { repository+: { yum+: { gpgKeys: if std.isArray(v=gpgKeys) then gpgKeys else [gpgKeys] } } },
              '#withGpgKeysMixin':: d.fn(help='"URIs of GPG keys."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='gpgKeys', type=d.T.array)]),
              withGpgKeysMixin(gpgKeys): { repository+: { yum+: { gpgKeys+: if std.isArray(v=gpgKeys) then gpgKeys else [gpgKeys] } } },
              '#withId':: d.fn(help='"Required. A one word, unique name for this repository. This is the `repo id` in the yum config file and also the `display_name` if `display_name` is omitted. This id is also used as the unique identifier when checking for resource conflicts."', args=[d.arg(name='id', type=d.T.string)]),
              withId(id): { repository+: { yum+: { id: id } } },
            },
            '#zypper':: d.obj(help='"A Zypper Repository."'),
            zypper: {
              '#withBaseUrl':: d.fn(help='"Required. The location of the repository directory."', args=[d.arg(name='baseUrl', type=d.T.string)]),
              withBaseUrl(baseUrl): { repository+: { zypper+: { baseUrl: baseUrl } } },
              '#withDisplayName':: d.fn(help='"The display name of the repository."', args=[d.arg(name='displayName', type=d.T.string)]),
              withDisplayName(displayName): { repository+: { zypper+: { displayName: displayName } } },
              '#withGpgKeys':: d.fn(help='"URIs of GPG keys."', args=[d.arg(name='gpgKeys', type=d.T.array)]),
              withGpgKeys(gpgKeys): { repository+: { zypper+: { gpgKeys: if std.isArray(v=gpgKeys) then gpgKeys else [gpgKeys] } } },
              '#withGpgKeysMixin':: d.fn(help='"URIs of GPG keys."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='gpgKeys', type=d.T.array)]),
              withGpgKeysMixin(gpgKeys): { repository+: { zypper+: { gpgKeys+: if std.isArray(v=gpgKeys) then gpgKeys else [gpgKeys] } } },
              '#withId':: d.fn(help='"Required. A one word, unique name for this repository. This is the `repo id` in the zypper config file and also the `display_name` if `display_name` is omitted. This id is also used as the unique identifier when checking for GuestPolicy conflicts."', args=[d.arg(name='id', type=d.T.string)]),
              withId(id): { repository+: { zypper+: { id: id } } },
            },
          },
          '#withId':: d.fn(help='"Required. The id of the resource with the following restrictions: * Must contain only lowercase letters, numbers, and hyphens. * Must start with a letter. * Must be between 1-63 characters. * Must end with a number or a letter. * Must be unique within the OS policy."', args=[d.arg(name='id', type=d.T.string)]),
          withId(id): { id: id },
        },
        '#withInventoryFilters':: d.fn(help="\"List of inventory filters for the resource group. The resources in this resource group are applied to the target VM if it satisfies at least one of the following inventory filters. For example, to apply this resource group to VMs running either `RHEL` or `CentOS` operating systems, specify 2 items for the list with following values: inventory_filters[0].os_short_name='rhel' and inventory_filters[1].os_short_name='centos' If the list is empty, this resource group will be applied to the target VM unconditionally.\"", args=[d.arg(name='inventoryFilters', type=d.T.array)]),
        withInventoryFilters(inventoryFilters): { inventoryFilters: if std.isArray(v=inventoryFilters) then inventoryFilters else [inventoryFilters] },
        '#withInventoryFiltersMixin':: d.fn(help="\"List of inventory filters for the resource group. The resources in this resource group are applied to the target VM if it satisfies at least one of the following inventory filters. For example, to apply this resource group to VMs running either `RHEL` or `CentOS` operating systems, specify 2 items for the list with following values: inventory_filters[0].os_short_name='rhel' and inventory_filters[1].os_short_name='centos' If the list is empty, this resource group will be applied to the target VM unconditionally.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='inventoryFilters', type=d.T.array)]),
        withInventoryFiltersMixin(inventoryFilters): { inventoryFilters+: if std.isArray(v=inventoryFilters) then inventoryFilters else [inventoryFilters] },
        '#withResources':: d.fn(help='"Required. List of resources configured for this resource group. The resources are executed in the exact order specified here."', args=[d.arg(name='resources', type=d.T.array)]),
        withResources(resources): { resources: if std.isArray(v=resources) then resources else [resources] },
        '#withResourcesMixin':: d.fn(help='"Required. List of resources configured for this resource group. The resources are executed in the exact order specified here."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resources', type=d.T.array)]),
        withResourcesMixin(resources): { resources+: if std.isArray(v=resources) then resources else [resources] },
      },
      '#withAllowNoResourceGroupMatch':: d.fn(help='"This flag determines the OS policy compliance status when none of the resource groups within the policy are applicable for a VM. Set this value to `true` if the policy needs to be reported as compliant even if the policy has nothing to validate or enforce."', args=[d.arg(name='allowNoResourceGroupMatch', type=d.T.boolean)]),
      withAllowNoResourceGroupMatch(allowNoResourceGroupMatch): { allowNoResourceGroupMatch: allowNoResourceGroupMatch },
      '#withDescription':: d.fn(help='"Policy description. Length of the description is limited to 1024 characters."', args=[d.arg(name='description', type=d.T.string)]),
      withDescription(description): { description: description },
      '#withId':: d.fn(help='"Required. The id of the OS policy with the following restrictions: * Must contain only lowercase letters, numbers, and hyphens. * Must start with a letter. * Must be between 1-63 characters. * Must end with a number or a letter. * Must be unique within the assignment."', args=[d.arg(name='id', type=d.T.string)]),
      withId(id): { id: id },
      '#withMode':: d.fn(help='"Required. Policy mode Possible values: MODE_UNSPECIFIED, VALIDATION, ENFORCEMENT"', args=[d.arg(name='mode', type=d.T.string)]),
      withMode(mode): { mode: mode },
      '#withResourceGroups':: d.fn(help='"Required. List of resource groups for the policy. For a particular VM, resource groups are evaluated in the order specified and the first resource group that is applicable is selected and the rest are ignored. If none of the resource groups are applicable for a VM, the VM is considered to be non-compliant w.r.t this policy. This behavior can be toggled by the flag `allow_no_resource_group_match`"', args=[d.arg(name='resourceGroups', type=d.T.array)]),
      withResourceGroups(resourceGroups): { resourceGroups: if std.isArray(v=resourceGroups) then resourceGroups else [resourceGroups] },
      '#withResourceGroupsMixin':: d.fn(help='"Required. List of resource groups for the policy. For a particular VM, resource groups are evaluated in the order specified and the first resource group that is applicable is selected and the rest are ignored. If none of the resource groups are applicable for a VM, the VM is considered to be non-compliant w.r.t this policy. This behavior can be toggled by the flag `allow_no_resource_group_match`"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resourceGroups', type=d.T.array)]),
      withResourceGroupsMixin(resourceGroups): { resourceGroups+: if std.isArray(v=resourceGroups) then resourceGroups else [resourceGroups] },
    },
    '#projectRef':: d.obj(help='"The Project that this resource belongs to."'),
    projectRef: {
      '#withExternal':: d.fn(help='"The project for the resource\\n\\nAllowed value: The Google Cloud resource name of a `Project` resource (format: `projects/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
      withExternal(external): { spec+: { projectRef+: { external: external } } },
      '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { projectRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { projectRef+: { namespace: namespace } } },
    },
    '#rollout':: d.obj(help='"Required. Rollout to deploy the OS policy assignment. A rollout is triggered in the following situations: 1) OSPolicyAssignment is created. 2) OSPolicyAssignment is updated and the update contains changes to one of the following fields: - instance_filter - os_policies 3) OSPolicyAssignment is deleted."'),
    rollout: {
      '#disruptionBudget':: d.obj(help='"Required. The maximum number (or percentage) of VMs per zone to disrupt at any given moment."'),
      disruptionBudget: {
        '#withFixed':: d.fn(help='"Specifies a fixed value."', args=[d.arg(name='fixed', type=d.T.integer)]),
        withFixed(fixed): { spec+: { rollout+: { disruptionBudget+: { fixed: fixed } } } },
        '#withPercent':: d.fn(help='"Specifies the relative value defined as a percentage, which will be multiplied by a reference value."', args=[d.arg(name='percent', type=d.T.integer)]),
        withPercent(percent): { spec+: { rollout+: { disruptionBudget+: { percent: percent } } } },
      },
      '#withMinWaitDuration':: d.fn(help='"Required. This determines the minimum duration of time to wait after the configuration changes are applied through the current rollout. A VM continues to count towards the `disruption_budget` at least until this duration of time has passed after configuration changes are applied."', args=[d.arg(name='minWaitDuration', type=d.T.string)]),
      withMinWaitDuration(minWaitDuration): { spec+: { rollout+: { minWaitDuration: minWaitDuration } } },
    },
    '#withDescription':: d.fn(help='"OS policy assignment description. Length of the description is limited to 1024 characters."', args=[d.arg(name='description', type=d.T.string)]),
    withDescription(description): { spec+: { description: description } },
    '#withLocation':: d.fn(help='"The location for the resource"', args=[d.arg(name='location', type=d.T.string)]),
    withLocation(location): { spec+: { location: location } },
    '#withOsPolicies':: d.fn(help='"Required. List of OS policies to be applied to the VMs."', args=[d.arg(name='osPolicies', type=d.T.array)]),
    withOsPolicies(osPolicies): { spec+: { osPolicies: if std.isArray(v=osPolicies) then osPolicies else [osPolicies] } },
    '#withOsPoliciesMixin':: d.fn(help='"Required. List of OS policies to be applied to the VMs."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='osPolicies', type=d.T.array)]),
    withOsPoliciesMixin(osPolicies): { spec+: { osPolicies+: if std.isArray(v=osPolicies) then osPolicies else [osPolicies] } },
    '#withResourceID':: d.fn(help='"Immutable. Optional. The name of the resource. Used for creation and acquisition. When unset, the value of `metadata.name` is used as the default."', args=[d.arg(name='resourceID', type=d.T.string)]),
    withResourceID(resourceID): { spec+: { resourceID: resourceID } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
