{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='dlpJobTrigger', url='', help=''),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of DLPJobTrigger', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'dlp.cnrm.cloud.google.com/v1beta1',
    kind: 'DLPJobTrigger',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help=''),
  spec: {
    '#inspectJob':: d.obj(help='"For inspect jobs, a snapshot of the configuration."'),
    inspectJob: {
      '#actions':: d.obj(help='"Actions to execute at the completion of the job."'),
      actions: {
        '#pubSub':: d.obj(help='"Publish a notification to a pubsub topic."'),
        pubSub: {
          '#topicRef':: d.obj(help=''),
          topicRef: {
            '#withExternal':: d.fn(help='"Cloud Pub/Sub topic to send notifications to. The topic must have given publishing access rights to the DLP API service account executing the long running DlpJob sending the notifications. Format is projects/{project}/topics/{topic}.\\n\\nAllowed value: The Google Cloud resource name of a `PubSubTopic` resource (format: `projects/{{project}}/topics/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
            withExternal(external): { pubSub+: { topicRef+: { external: external } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { pubSub+: { topicRef+: { name: name } } },
            '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
            withNamespace(namespace): { pubSub+: { topicRef+: { namespace: namespace } } },
          },
        },
        '#saveFindings':: d.obj(help='"Save resulting findings in a provided location."'),
        saveFindings: {
          '#outputConfig':: d.obj(help='"Location to store findings outside of DLP."'),
          outputConfig: {
            '#table':: d.obj(help='"Store findings in an existing table or a new table in an existing dataset. If table_id is not set a new one will be generated for you with the following format: dlp_googleapis_yyyy_mm_dd_[dlp_job_id]. Pacific timezone will be used for generating the date details. For Inspect, each column in an existing output table must have the same name, type, and mode of a field in the `Finding` object. For Risk, an existing output table should be the output of a previous Risk analysis job run on the same source table, with the same privacy metric and quasi-identifiers. Risk jobs that analyze the same table but compute a different privacy metric, or use different sets of quasi-identifiers, cannot store their results in the same table."'),
            table: {
              '#datasetRef':: d.obj(help=''),
              datasetRef: {
                '#withExternal':: d.fn(help='"Dataset ID of the table.\\n\\nAllowed value: The Google Cloud resource name of a `BigQueryDataset` resource (format: `projects/{{project}}/datasets/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
                withExternal(external): { saveFindings+: { outputConfig+: { table+: { datasetRef+: { external: external } } } } },
                '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { saveFindings+: { outputConfig+: { table+: { datasetRef+: { name: name } } } } },
                '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { saveFindings+: { outputConfig+: { table+: { datasetRef+: { namespace: namespace } } } } },
              },
              '#projectRef':: d.obj(help=''),
              projectRef: {
                '#withExternal':: d.fn(help='"The Google Cloud Platform project ID of the project containing the table. If omitted, project ID is inferred from the API call.\\n\\nAllowed value: The Google Cloud resource name of a `Project` resource (format: `projects/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
                withExternal(external): { saveFindings+: { outputConfig+: { table+: { projectRef+: { external: external } } } } },
                '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { saveFindings+: { outputConfig+: { table+: { projectRef+: { name: name } } } } },
                '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { saveFindings+: { outputConfig+: { table+: { projectRef+: { namespace: namespace } } } } },
              },
              '#tableRef':: d.obj(help=''),
              tableRef: {
                '#withExternal':: d.fn(help='"Name of the table.\\n\\nAllowed value: The Google Cloud resource name of a `BigQueryTable` resource (format: `projects/{{project}}/datasets/{{dataset_id}}/tables/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
                withExternal(external): { saveFindings+: { outputConfig+: { table+: { tableRef+: { external: external } } } } },
                '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { saveFindings+: { outputConfig+: { table+: { tableRef+: { name: name } } } } },
                '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { saveFindings+: { outputConfig+: { table+: { tableRef+: { namespace: namespace } } } } },
              },
            },
            '#withDlpStorage':: d.fn(help='"Store findings directly to DLP. If neither this or bigquery is chosen only summary stats of total infotype count will be stored. Quotes will not be stored to dlp findings. If quotes are needed, store to BigQuery. Currently only for inspect jobs."', args=[d.arg(name='dlpStorage', type=d.T.object)]),
            withDlpStorage(dlpStorage): { saveFindings+: { outputConfig+: { dlpStorage: dlpStorage } } },
            '#withDlpStorageMixin':: d.fn(help='"Store findings directly to DLP. If neither this or bigquery is chosen only summary stats of total infotype count will be stored. Quotes will not be stored to dlp findings. If quotes are needed, store to BigQuery. Currently only for inspect jobs."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dlpStorage', type=d.T.object)]),
            withDlpStorageMixin(dlpStorage): { saveFindings+: { outputConfig+: { dlpStorage+: dlpStorage } } },
            '#withOutputSchema':: d.fn(help='"Schema used for writing the findings for Inspect jobs. This field is only used for Inspect and must be unspecified for Risk jobs. Columns are derived from the `Finding` object. If appending to an existing table, any columns from the predefined schema that are missing will be added. No columns in the existing table will be deleted. If unspecified, then all available columns will be used for a new table or an (existing) table with no schema, and no changes will be made to an existing table that has a schema. Only for use with external storage. Possible values: OUTPUT_SCHEMA_UNSPECIFIED, BASIC_COLUMNS, GCS_COLUMNS, DATASTORE_COLUMNS, BIG_QUERY_COLUMNS, ALL_COLUMNS"', args=[d.arg(name='outputSchema', type=d.T.string)]),
            withOutputSchema(outputSchema): { saveFindings+: { outputConfig+: { outputSchema: outputSchema } } },
          },
        },
        '#withJobNotificationEmails':: d.fn(help="\"Enable email notification for project owners and editors on job's completion/failure.\"", args=[d.arg(name='jobNotificationEmails', type=d.T.object)]),
        withJobNotificationEmails(jobNotificationEmails): { jobNotificationEmails: jobNotificationEmails },
        '#withJobNotificationEmailsMixin':: d.fn(help="\"Enable email notification for project owners and editors on job's completion/failure.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='jobNotificationEmails', type=d.T.object)]),
        withJobNotificationEmailsMixin(jobNotificationEmails): { jobNotificationEmails+: jobNotificationEmails },
        '#withPublishFindingsToCloudDataCatalog':: d.fn(help='"Publish findings to Cloud Datahub."', args=[d.arg(name='publishFindingsToCloudDataCatalog', type=d.T.object)]),
        withPublishFindingsToCloudDataCatalog(publishFindingsToCloudDataCatalog): { publishFindingsToCloudDataCatalog: publishFindingsToCloudDataCatalog },
        '#withPublishFindingsToCloudDataCatalogMixin':: d.fn(help='"Publish findings to Cloud Datahub."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='publishFindingsToCloudDataCatalog', type=d.T.object)]),
        withPublishFindingsToCloudDataCatalogMixin(publishFindingsToCloudDataCatalog): { publishFindingsToCloudDataCatalog+: publishFindingsToCloudDataCatalog },
        '#withPublishSummaryToCscc':: d.fn(help='"Publish summary to Cloud Security Command Center (Alpha)."', args=[d.arg(name='publishSummaryToCscc', type=d.T.object)]),
        withPublishSummaryToCscc(publishSummaryToCscc): { publishSummaryToCscc: publishSummaryToCscc },
        '#withPublishSummaryToCsccMixin':: d.fn(help='"Publish summary to Cloud Security Command Center (Alpha)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='publishSummaryToCscc', type=d.T.object)]),
        withPublishSummaryToCsccMixin(publishSummaryToCscc): { publishSummaryToCscc+: publishSummaryToCscc },
        '#withPublishToStackdriver':: d.fn(help='"Enable Stackdriver metric dlp.googleapis.com/finding_count."', args=[d.arg(name='publishToStackdriver', type=d.T.object)]),
        withPublishToStackdriver(publishToStackdriver): { publishToStackdriver: publishToStackdriver },
        '#withPublishToStackdriverMixin':: d.fn(help='"Enable Stackdriver metric dlp.googleapis.com/finding_count."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='publishToStackdriver', type=d.T.object)]),
        withPublishToStackdriverMixin(publishToStackdriver): { publishToStackdriver+: publishToStackdriver },
      },
      '#inspectConfig':: d.obj(help='"How and what to scan for."'),
      inspectConfig: {
        '#customInfoTypes':: d.obj(help='"CustomInfoTypes provided by the user. See https://cloud.google.com/dlp/docs/creating-custom-infotypes to learn more."'),
        customInfoTypes: {
          '#detectionRules':: d.obj(help='"Set of detection rules to apply to all findings of this CustomInfoType. Rules are applied in order that they are specified. Not supported for the `surrogate_type` CustomInfoType."'),
          detectionRules: {
            '#hotwordRule':: d.obj(help='"Hotword-based detection rule."'),
            hotwordRule: {
              '#hotwordRegex':: d.obj(help='"Regular expression pattern defining what qualifies as a hotword."'),
              hotwordRegex: {
                '#withGroupIndexes':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."', args=[d.arg(name='groupIndexes', type=d.T.array)]),
                withGroupIndexes(groupIndexes): { hotwordRule+: { hotwordRegex+: { groupIndexes: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } } },
                '#withGroupIndexesMixin':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='groupIndexes', type=d.T.array)]),
                withGroupIndexesMixin(groupIndexes): { hotwordRule+: { hotwordRegex+: { groupIndexes+: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } } },
                '#withPattern':: d.fn(help='"Pattern defining the regular expression. Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub."', args=[d.arg(name='pattern', type=d.T.string)]),
                withPattern(pattern): { hotwordRule+: { hotwordRegex+: { pattern: pattern } } },
              },
              '#likelihoodAdjustment':: d.obj(help='"Likelihood adjustment to apply to all matching findings."'),
              likelihoodAdjustment: {
                '#withFixedLikelihood':: d.fn(help='"Set the likelihood of a finding to a fixed value. Possible values: LIKELIHOOD_UNSPECIFIED, VERY_UNLIKELY, UNLIKELY, POSSIBLE, LIKELY, VERY_LIKELY"', args=[d.arg(name='fixedLikelihood', type=d.T.string)]),
                withFixedLikelihood(fixedLikelihood): { hotwordRule+: { likelihoodAdjustment+: { fixedLikelihood: fixedLikelihood } } },
                '#withRelativeLikelihood':: d.fn(help='"Increase or decrease the likelihood by the specified number of levels. For example, if a finding would be `POSSIBLE` without the detection rule and `relative_likelihood` is 1, then it is upgraded to `LIKELY`, while a value of -1 would downgrade it to `UNLIKELY`. Likelihood may never drop below `VERY_UNLIKELY` or exceed `VERY_LIKELY`, so applying an adjustment of 1 followed by an adjustment of -1 when base likelihood is `VERY_LIKELY` will result in a final likelihood of `LIKELY`."', args=[d.arg(name='relativeLikelihood', type=d.T.integer)]),
                withRelativeLikelihood(relativeLikelihood): { hotwordRule+: { likelihoodAdjustment+: { relativeLikelihood: relativeLikelihood } } },
              },
              '#proximity':: d.obj(help='"Proximity of the finding within which the entire hotword must reside. The total length of the window cannot exceed 1000 characters. Note that the finding itself will be included in the window, so that hotwords may be used to match substrings of the finding itself. For example, the certainty of a phone number regex \\"(d{3}) d{3}-d{4}\\" could be adjusted upwards if the area code is known to be the local area code of a company office using the hotword regex \\"(xxx)\\", where \\"xxx\\" is the area code in question."'),
              proximity: {
                '#withWindowAfter':: d.fn(help='"Number of characters after the finding to consider."', args=[d.arg(name='windowAfter', type=d.T.integer)]),
                withWindowAfter(windowAfter): { hotwordRule+: { proximity+: { windowAfter: windowAfter } } },
                '#withWindowBefore':: d.fn(help='"Number of characters before the finding to consider."', args=[d.arg(name='windowBefore', type=d.T.integer)]),
                withWindowBefore(windowBefore): { hotwordRule+: { proximity+: { windowBefore: windowBefore } } },
              },
            },
          },
          '#dictionary':: d.obj(help='"A list of phrases to detect as a CustomInfoType."'),
          dictionary: {
            '#cloudStoragePath':: d.obj(help='"Newline-delimited file of words in Cloud Storage. Only a single file is accepted."'),
            cloudStoragePath: {
              '#withPath':: d.fn(help='"A url representing a file or path (no wildcards) in Cloud Storage. Example: gs://[BUCKET_NAME]/dictionary.txt"', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { dictionary+: { cloudStoragePath+: { path: path } } },
            },
            '#wordList':: d.obj(help='"List of words or phrases to search for."'),
            wordList: {
              '#withWords':: d.fn(help='"Words or phrases defining the dictionary. The dictionary must contain at least one phrase and every phrase must contain at least 2 characters that are letters or digits. [required]"', args=[d.arg(name='words', type=d.T.array)]),
              withWords(words): { dictionary+: { wordList+: { words: if std.isArray(v=words) then words else [words] } } },
              '#withWordsMixin':: d.fn(help='"Words or phrases defining the dictionary. The dictionary must contain at least one phrase and every phrase must contain at least 2 characters that are letters or digits. [required]"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='words', type=d.T.array)]),
              withWordsMixin(words): { dictionary+: { wordList+: { words+: if std.isArray(v=words) then words else [words] } } },
            },
          },
          '#infoType':: d.obj(help='"CustomInfoType can either be a new infoType, or an extension of built-in infoType, when the name matches one of existing infoTypes and that infoType is specified in `InspectContent.info_types` field. Specifying the latter adds findings to the one detected by the system. If built-in info type is not specified in `InspectContent.info_types` list then the name is treated as a custom info type."'),
          infoType: {
            '#withName':: d.fn(help='"Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { infoType+: { name: name } },
            '#withVersion':: d.fn(help='"Optional version name for this InfoType."', args=[d.arg(name='version', type=d.T.string)]),
            withVersion(version): { infoType+: { version: version } },
          },
          '#regex':: d.obj(help='"Regular expression based CustomInfoType."'),
          regex: {
            '#withGroupIndexes':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."', args=[d.arg(name='groupIndexes', type=d.T.array)]),
            withGroupIndexes(groupIndexes): { regex+: { groupIndexes: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } },
            '#withGroupIndexesMixin':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='groupIndexes', type=d.T.array)]),
            withGroupIndexesMixin(groupIndexes): { regex+: { groupIndexes+: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } },
            '#withPattern':: d.fn(help='"Pattern defining the regular expression. Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub."', args=[d.arg(name='pattern', type=d.T.string)]),
            withPattern(pattern): { regex+: { pattern: pattern } },
          },
          '#storedType':: d.obj(help='"Load an existing `StoredInfoType` resource for use in `InspectDataSource`. Not currently supported in `InspectContent`."'),
          storedType: {
            '#nameRef':: d.obj(help=''),
            nameRef: {
              '#withExternal':: d.fn(help='"Resource name of the requested `StoredInfoType`, for example `organizations/433245324/storedInfoTypes/432452342` or `projects/project-id/storedInfoTypes/432452342`.\\n\\nAllowed value: The Google Cloud resource name of a `DLPStoredInfoType` resource (format: `{{parent}}/storedInfoTypes/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
              withExternal(external): { storedType+: { nameRef+: { external: external } } },
              '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { storedType+: { nameRef+: { name: name } } },
              '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
              withNamespace(namespace): { storedType+: { nameRef+: { namespace: namespace } } },
            },
            '#withCreateTime':: d.fn(help='"Timestamp indicating when the version of the `StoredInfoType` used for inspection was created. Output-only field, populated by the system."', args=[d.arg(name='createTime', type=d.T.string)]),
            withCreateTime(createTime): { storedType+: { createTime: createTime } },
          },
          '#withDetectionRules':: d.fn(help='"Set of detection rules to apply to all findings of this CustomInfoType. Rules are applied in order that they are specified. Not supported for the `surrogate_type` CustomInfoType."', args=[d.arg(name='detectionRules', type=d.T.array)]),
          withDetectionRules(detectionRules): { detectionRules: if std.isArray(v=detectionRules) then detectionRules else [detectionRules] },
          '#withDetectionRulesMixin':: d.fn(help='"Set of detection rules to apply to all findings of this CustomInfoType. Rules are applied in order that they are specified. Not supported for the `surrogate_type` CustomInfoType."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='detectionRules', type=d.T.array)]),
          withDetectionRulesMixin(detectionRules): { detectionRules+: if std.isArray(v=detectionRules) then detectionRules else [detectionRules] },
          '#withExclusionType':: d.fn(help='"If set to EXCLUSION_TYPE_EXCLUDE this infoType will not cause a finding to be returned. It still can be used for rules matching. Possible values: EXCLUSION_TYPE_UNSPECIFIED, EXCLUSION_TYPE_EXCLUDE"', args=[d.arg(name='exclusionType', type=d.T.string)]),
          withExclusionType(exclusionType): { exclusionType: exclusionType },
          '#withLikelihood':: d.fn(help='"Likelihood to return for this CustomInfoType. This base value can be altered by a detection rule if the finding meets the criteria specified by the rule. Defaults to `VERY_LIKELY` if not specified. Possible values: LIKELIHOOD_UNSPECIFIED, VERY_UNLIKELY, UNLIKELY, POSSIBLE, LIKELY, VERY_LIKELY"', args=[d.arg(name='likelihood', type=d.T.string)]),
          withLikelihood(likelihood): { likelihood: likelihood },
          '#withSurrogateType':: d.fn(help='"Message for detecting output from deidentification transformations that support reversing."', args=[d.arg(name='surrogateType', type=d.T.object)]),
          withSurrogateType(surrogateType): { surrogateType: surrogateType },
          '#withSurrogateTypeMixin':: d.fn(help='"Message for detecting output from deidentification transformations that support reversing."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='surrogateType', type=d.T.object)]),
          withSurrogateTypeMixin(surrogateType): { surrogateType+: surrogateType },
        },
        '#infoTypes':: d.obj(help='"Restricts what info_types to look for. The values must correspond to InfoType values returned by ListInfoTypes or listed at https://cloud.google.com/dlp/docs/infotypes-reference. When no InfoTypes or CustomInfoTypes are specified in a request, the system may automatically choose what detectors to run. By default this may be all types, but may change over time as detectors are updated. If you need precise control and predictability as to what detectors are run you should specify specific InfoTypes listed in the reference, otherwise a default list will be used, which may change over time."'),
        infoTypes: {
          '#withName':: d.fn(help='"Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#limits':: d.obj(help='"Configuration to control the number of findings returned. This is not used for data profiling."'),
        limits: {
          '#maxFindingsPerInfoType':: d.obj(help='"Configuration of findings limit given for specified infoTypes."'),
          maxFindingsPerInfoType: {
            '#infoType':: d.obj(help='"Type of information the findings limit applies to. Only one limit per info_type should be provided. If InfoTypeLimit does not have an info_type, the DLP API applies the limit against all info_types that are found but not specified in another InfoTypeLimit."'),
            infoType: {
              '#withName':: d.fn(help='"Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { infoType+: { name: name } },
              '#withVersion':: d.fn(help='"Optional version name for this InfoType."', args=[d.arg(name='version', type=d.T.string)]),
              withVersion(version): { infoType+: { version: version } },
            },
            '#withMaxFindings':: d.fn(help='"Max findings limit for the given infoType."', args=[d.arg(name='maxFindings', type=d.T.integer)]),
            withMaxFindings(maxFindings): { maxFindings: maxFindings },
          },
          '#withMaxFindingsPerInfoType':: d.fn(help='"Configuration of findings limit given for specified infoTypes."', args=[d.arg(name='maxFindingsPerInfoType', type=d.T.array)]),
          withMaxFindingsPerInfoType(maxFindingsPerInfoType): { spec+: { inspectJob+: { inspectConfig+: { limits+: { maxFindingsPerInfoType: if std.isArray(v=maxFindingsPerInfoType) then maxFindingsPerInfoType else [maxFindingsPerInfoType] } } } } },
          '#withMaxFindingsPerInfoTypeMixin':: d.fn(help='"Configuration of findings limit given for specified infoTypes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maxFindingsPerInfoType', type=d.T.array)]),
          withMaxFindingsPerInfoTypeMixin(maxFindingsPerInfoType): { spec+: { inspectJob+: { inspectConfig+: { limits+: { maxFindingsPerInfoType+: if std.isArray(v=maxFindingsPerInfoType) then maxFindingsPerInfoType else [maxFindingsPerInfoType] } } } } },
          '#withMaxFindingsPerItem':: d.fn(help='"Max number of findings that will be returned for each item scanned. When set within `InspectJobConfig`, the maximum returned is 2000 regardless if this is set higher. When set within `InspectContentRequest`, this field is ignored."', args=[d.arg(name='maxFindingsPerItem', type=d.T.integer)]),
          withMaxFindingsPerItem(maxFindingsPerItem): { spec+: { inspectJob+: { inspectConfig+: { limits+: { maxFindingsPerItem: maxFindingsPerItem } } } } },
          '#withMaxFindingsPerRequest':: d.fn(help='"Max number of findings that will be returned per request/job. When set within `InspectContentRequest`, the maximum returned is 2000 regardless if this is set higher."', args=[d.arg(name='maxFindingsPerRequest', type=d.T.integer)]),
          withMaxFindingsPerRequest(maxFindingsPerRequest): { spec+: { inspectJob+: { inspectConfig+: { limits+: { maxFindingsPerRequest: maxFindingsPerRequest } } } } },
        },
        '#ruleSet':: d.obj(help='"Set of rules to apply to the findings for this InspectConfig. Exclusion rules, contained in the set are executed in the end, other rules are executed in the order they are specified for each info type."'),
        ruleSet: {
          '#infoTypes':: d.obj(help='"List of infoTypes this rule set is applied to."'),
          infoTypes: {
            '#withName':: d.fn(help='"Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withVersion':: d.fn(help='"Optional version name for this InfoType."', args=[d.arg(name='version', type=d.T.string)]),
            withVersion(version): { version: version },
          },
          '#rules':: d.obj(help='"Set of rules to be applied to infoTypes. The rules are applied in order."'),
          rules: {
            '#exclusionRule':: d.obj(help='"Exclusion rule."'),
            exclusionRule: {
              '#dictionary':: d.obj(help='"Dictionary which defines the rule."'),
              dictionary: {
                '#cloudStoragePath':: d.obj(help='"Newline-delimited file of words in Cloud Storage. Only a single file is accepted."'),
                cloudStoragePath: {
                  '#withPath':: d.fn(help='"A url representing a file or path (no wildcards) in Cloud Storage. Example: gs://[BUCKET_NAME]/dictionary.txt"', args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { exclusionRule+: { dictionary+: { cloudStoragePath+: { path: path } } } },
                },
                '#wordList':: d.obj(help='"List of words or phrases to search for."'),
                wordList: {
                  '#withWords':: d.fn(help='"Words or phrases defining the dictionary. The dictionary must contain at least one phrase and every phrase must contain at least 2 characters that are letters or digits. [required]"', args=[d.arg(name='words', type=d.T.array)]),
                  withWords(words): { exclusionRule+: { dictionary+: { wordList+: { words: if std.isArray(v=words) then words else [words] } } } },
                  '#withWordsMixin':: d.fn(help='"Words or phrases defining the dictionary. The dictionary must contain at least one phrase and every phrase must contain at least 2 characters that are letters or digits. [required]"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='words', type=d.T.array)]),
                  withWordsMixin(words): { exclusionRule+: { dictionary+: { wordList+: { words+: if std.isArray(v=words) then words else [words] } } } },
                },
              },
              '#excludeInfoTypes':: d.obj(help='"Set of infoTypes for which findings would affect this rule."'),
              excludeInfoTypes: {
                '#infoTypes':: d.obj(help='"InfoType list in ExclusionRule rule drops a finding when it overlaps or contained within with a finding of an infoType from this list. For example, for `InspectionRuleSet.info_types` containing \\"PHONE_NUMBER\\"` and `exclusion_rule` containing `exclude_info_types.info_types` with \\"EMAIL_ADDRESS\\" the phone number findings are dropped if they overlap with EMAIL_ADDRESS finding. That leads to \\"555-222-2222@example.org\\" to generate only a single finding, namely email address."'),
                infoTypes: {
                  '#withName':: d.fn(help='"Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withVersion':: d.fn(help='"Optional version name for this InfoType."', args=[d.arg(name='version', type=d.T.string)]),
                  withVersion(version): { version: version },
                },
                '#withInfoTypes':: d.fn(help='"InfoType list in ExclusionRule rule drops a finding when it overlaps or contained within with a finding of an infoType from this list. For example, for `InspectionRuleSet.info_types` containing \\"PHONE_NUMBER\\"` and `exclusion_rule` containing `exclude_info_types.info_types` with \\"EMAIL_ADDRESS\\" the phone number findings are dropped if they overlap with EMAIL_ADDRESS finding. That leads to \\"555-222-2222@example.org\\" to generate only a single finding, namely email address."', args=[d.arg(name='infoTypes', type=d.T.array)]),
                withInfoTypes(infoTypes): { exclusionRule+: { excludeInfoTypes+: { infoTypes: if std.isArray(v=infoTypes) then infoTypes else [infoTypes] } } },
                '#withInfoTypesMixin':: d.fn(help='"InfoType list in ExclusionRule rule drops a finding when it overlaps or contained within with a finding of an infoType from this list. For example, for `InspectionRuleSet.info_types` containing \\"PHONE_NUMBER\\"` and `exclusion_rule` containing `exclude_info_types.info_types` with \\"EMAIL_ADDRESS\\" the phone number findings are dropped if they overlap with EMAIL_ADDRESS finding. That leads to \\"555-222-2222@example.org\\" to generate only a single finding, namely email address."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='infoTypes', type=d.T.array)]),
                withInfoTypesMixin(infoTypes): { exclusionRule+: { excludeInfoTypes+: { infoTypes+: if std.isArray(v=infoTypes) then infoTypes else [infoTypes] } } },
              },
              '#regex':: d.obj(help='"Regular expression which defines the rule."'),
              regex: {
                '#withGroupIndexes':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."', args=[d.arg(name='groupIndexes', type=d.T.array)]),
                withGroupIndexes(groupIndexes): { exclusionRule+: { regex+: { groupIndexes: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } } },
                '#withGroupIndexesMixin':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='groupIndexes', type=d.T.array)]),
                withGroupIndexesMixin(groupIndexes): { exclusionRule+: { regex+: { groupIndexes+: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } } },
                '#withPattern':: d.fn(help='"Pattern defining the regular expression. Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub."', args=[d.arg(name='pattern', type=d.T.string)]),
                withPattern(pattern): { exclusionRule+: { regex+: { pattern: pattern } } },
              },
              '#withMatchingType':: d.fn(help='"How the rule is applied, see MatchingType documentation for details. Possible values: MATCHING_TYPE_UNSPECIFIED, MATCHING_TYPE_FULL_MATCH, MATCHING_TYPE_PARTIAL_MATCH, MATCHING_TYPE_INVERSE_MATCH"', args=[d.arg(name='matchingType', type=d.T.string)]),
              withMatchingType(matchingType): { exclusionRule+: { matchingType: matchingType } },
            },
            '#hotwordRule':: d.obj(help=''),
            hotwordRule: {
              '#hotwordRegex':: d.obj(help='"Regular expression pattern defining what qualifies as a hotword."'),
              hotwordRegex: {
                '#withGroupIndexes':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."', args=[d.arg(name='groupIndexes', type=d.T.array)]),
                withGroupIndexes(groupIndexes): { hotwordRule+: { hotwordRegex+: { groupIndexes: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } } },
                '#withGroupIndexesMixin':: d.fn(help='"The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='groupIndexes', type=d.T.array)]),
                withGroupIndexesMixin(groupIndexes): { hotwordRule+: { hotwordRegex+: { groupIndexes+: if std.isArray(v=groupIndexes) then groupIndexes else [groupIndexes] } } },
                '#withPattern':: d.fn(help='"Pattern defining the regular expression. Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub."', args=[d.arg(name='pattern', type=d.T.string)]),
                withPattern(pattern): { hotwordRule+: { hotwordRegex+: { pattern: pattern } } },
              },
              '#likelihoodAdjustment':: d.obj(help='"Likelihood adjustment to apply to all matching findings."'),
              likelihoodAdjustment: {
                '#withFixedLikelihood':: d.fn(help='"Set the likelihood of a finding to a fixed value. Possible values: LIKELIHOOD_UNSPECIFIED, VERY_UNLIKELY, UNLIKELY, POSSIBLE, LIKELY, VERY_LIKELY"', args=[d.arg(name='fixedLikelihood', type=d.T.string)]),
                withFixedLikelihood(fixedLikelihood): { hotwordRule+: { likelihoodAdjustment+: { fixedLikelihood: fixedLikelihood } } },
                '#withRelativeLikelihood':: d.fn(help='"Increase or decrease the likelihood by the specified number of levels. For example, if a finding would be `POSSIBLE` without the detection rule and `relative_likelihood` is 1, then it is upgraded to `LIKELY`, while a value of -1 would downgrade it to `UNLIKELY`. Likelihood may never drop below `VERY_UNLIKELY` or exceed `VERY_LIKELY`, so applying an adjustment of 1 followed by an adjustment of -1 when base likelihood is `VERY_LIKELY` will result in a final likelihood of `LIKELY`."', args=[d.arg(name='relativeLikelihood', type=d.T.integer)]),
                withRelativeLikelihood(relativeLikelihood): { hotwordRule+: { likelihoodAdjustment+: { relativeLikelihood: relativeLikelihood } } },
              },
              '#proximity':: d.obj(help='"Proximity of the finding within which the entire hotword must reside. The total length of the window cannot exceed 1000 characters. Note that the finding itself will be included in the window, so that hotwords may be used to match substrings of the finding itself. For example, the certainty of a phone number regex \\"(d{3}) d{3}-d{4}\\" could be adjusted upwards if the area code is known to be the local area code of a company office using the hotword regex \\"(xxx)\\", where \\"xxx\\" is the area code in question."'),
              proximity: {
                '#withWindowAfter':: d.fn(help='"Number of characters after the finding to consider."', args=[d.arg(name='windowAfter', type=d.T.integer)]),
                withWindowAfter(windowAfter): { hotwordRule+: { proximity+: { windowAfter: windowAfter } } },
                '#withWindowBefore':: d.fn(help='"Number of characters before the finding to consider."', args=[d.arg(name='windowBefore', type=d.T.integer)]),
                withWindowBefore(windowBefore): { hotwordRule+: { proximity+: { windowBefore: windowBefore } } },
              },
            },
          },
          '#withInfoTypes':: d.fn(help='"List of infoTypes this rule set is applied to."', args=[d.arg(name='infoTypes', type=d.T.array)]),
          withInfoTypes(infoTypes): { infoTypes: if std.isArray(v=infoTypes) then infoTypes else [infoTypes] },
          '#withInfoTypesMixin':: d.fn(help='"List of infoTypes this rule set is applied to."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='infoTypes', type=d.T.array)]),
          withInfoTypesMixin(infoTypes): { infoTypes+: if std.isArray(v=infoTypes) then infoTypes else [infoTypes] },
          '#withRules':: d.fn(help='"Set of rules to be applied to infoTypes. The rules are applied in order."', args=[d.arg(name='rules', type=d.T.array)]),
          withRules(rules): { rules: if std.isArray(v=rules) then rules else [rules] },
          '#withRulesMixin':: d.fn(help='"Set of rules to be applied to infoTypes. The rules are applied in order."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='rules', type=d.T.array)]),
          withRulesMixin(rules): { rules+: if std.isArray(v=rules) then rules else [rules] },
        },
        '#withCustomInfoTypes':: d.fn(help='"CustomInfoTypes provided by the user. See https://cloud.google.com/dlp/docs/creating-custom-infotypes to learn more."', args=[d.arg(name='customInfoTypes', type=d.T.array)]),
        withCustomInfoTypes(customInfoTypes): { spec+: { inspectJob+: { inspectConfig+: { customInfoTypes: if std.isArray(v=customInfoTypes) then customInfoTypes else [customInfoTypes] } } } },
        '#withCustomInfoTypesMixin':: d.fn(help='"CustomInfoTypes provided by the user. See https://cloud.google.com/dlp/docs/creating-custom-infotypes to learn more."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='customInfoTypes', type=d.T.array)]),
        withCustomInfoTypesMixin(customInfoTypes): { spec+: { inspectJob+: { inspectConfig+: { customInfoTypes+: if std.isArray(v=customInfoTypes) then customInfoTypes else [customInfoTypes] } } } },
        '#withExcludeInfoTypes':: d.fn(help='"When true, excludes type information of the findings. This is not used for data profiling."', args=[d.arg(name='excludeInfoTypes', type=d.T.boolean)]),
        withExcludeInfoTypes(excludeInfoTypes): { spec+: { inspectJob+: { inspectConfig+: { excludeInfoTypes: excludeInfoTypes } } } },
        '#withIncludeQuote':: d.fn(help='"When true, a contextual quote from the data that triggered a finding is included in the response; see Finding.quote. This is not used for data profiling."', args=[d.arg(name='includeQuote', type=d.T.boolean)]),
        withIncludeQuote(includeQuote): { spec+: { inspectJob+: { inspectConfig+: { includeQuote: includeQuote } } } },
        '#withInfoTypes':: d.fn(help='"Restricts what info_types to look for. The values must correspond to InfoType values returned by ListInfoTypes or listed at https://cloud.google.com/dlp/docs/infotypes-reference. When no InfoTypes or CustomInfoTypes are specified in a request, the system may automatically choose what detectors to run. By default this may be all types, but may change over time as detectors are updated. If you need precise control and predictability as to what detectors are run you should specify specific InfoTypes listed in the reference, otherwise a default list will be used, which may change over time."', args=[d.arg(name='infoTypes', type=d.T.array)]),
        withInfoTypes(infoTypes): { spec+: { inspectJob+: { inspectConfig+: { infoTypes: if std.isArray(v=infoTypes) then infoTypes else [infoTypes] } } } },
        '#withInfoTypesMixin':: d.fn(help='"Restricts what info_types to look for. The values must correspond to InfoType values returned by ListInfoTypes or listed at https://cloud.google.com/dlp/docs/infotypes-reference. When no InfoTypes or CustomInfoTypes are specified in a request, the system may automatically choose what detectors to run. By default this may be all types, but may change over time as detectors are updated. If you need precise control and predictability as to what detectors are run you should specify specific InfoTypes listed in the reference, otherwise a default list will be used, which may change over time."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='infoTypes', type=d.T.array)]),
        withInfoTypesMixin(infoTypes): { spec+: { inspectJob+: { inspectConfig+: { infoTypes+: if std.isArray(v=infoTypes) then infoTypes else [infoTypes] } } } },
        '#withMinLikelihood':: d.fn(help='"Only returns findings equal or above this threshold. The default is POSSIBLE. See https://cloud.google.com/dlp/docs/likelihood to learn more. Possible values: LIKELIHOOD_UNSPECIFIED, VERY_UNLIKELY, UNLIKELY, POSSIBLE, LIKELY, VERY_LIKELY"', args=[d.arg(name='minLikelihood', type=d.T.string)]),
        withMinLikelihood(minLikelihood): { spec+: { inspectJob+: { inspectConfig+: { minLikelihood: minLikelihood } } } },
        '#withRuleSet':: d.fn(help='"Set of rules to apply to the findings for this InspectConfig. Exclusion rules, contained in the set are executed in the end, other rules are executed in the order they are specified for each info type."', args=[d.arg(name='ruleSet', type=d.T.array)]),
        withRuleSet(ruleSet): { spec+: { inspectJob+: { inspectConfig+: { ruleSet: if std.isArray(v=ruleSet) then ruleSet else [ruleSet] } } } },
        '#withRuleSetMixin':: d.fn(help='"Set of rules to apply to the findings for this InspectConfig. Exclusion rules, contained in the set are executed in the end, other rules are executed in the order they are specified for each info type."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ruleSet', type=d.T.array)]),
        withRuleSetMixin(ruleSet): { spec+: { inspectJob+: { inspectConfig+: { ruleSet+: if std.isArray(v=ruleSet) then ruleSet else [ruleSet] } } } },
      },
      '#inspectTemplateRef':: d.obj(help=''),
      inspectTemplateRef: {
        '#withExternal':: d.fn(help='"If provided, will be used as the default for all values in InspectConfig. `inspect_config` will be merged into the values persisted as part of the template.\\n\\nAllowed value: The Google Cloud resource name of a `DLPInspectTemplate` resource (format: `{{parent}}/inspectTemplates/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
        withExternal(external): { spec+: { inspectJob+: { inspectTemplateRef+: { external: external } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { inspectJob+: { inspectTemplateRef+: { name: name } } } },
        '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { inspectJob+: { inspectTemplateRef+: { namespace: namespace } } } },
      },
      '#storageConfig':: d.obj(help='"The data to scan."'),
      storageConfig: {
        '#bigQueryOptions':: d.obj(help='"BigQuery options."'),
        bigQueryOptions: {
          '#excludedFields':: d.obj(help='"References to fields excluded from scanning. This allows you to skip inspection of entire columns which you know have no findings."'),
          excludedFields: {
            '#withName':: d.fn(help='"Name describing the field."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
          },
          '#identifyingFields':: d.obj(help='"Table fields that may uniquely identify a row within the table. When `actions.saveFindings.outputConfig.table` is specified, the values of columns specified here are available in the output table under `location.content_locations.record_location.record_key.id_values`. Nested fields such as `person.birthdate.year` are allowed."'),
          identifyingFields: {
            '#withName':: d.fn(help='"Name describing the field."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
          },
          '#includedFields':: d.obj(help='"Limit scanning only to these fields."'),
          includedFields: {
            '#withName':: d.fn(help='"Name describing the field."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
          },
          '#tableReference':: d.obj(help='"Complete BigQuery table reference."'),
          tableReference: {
            '#datasetRef':: d.obj(help=''),
            datasetRef: {
              '#withExternal':: d.fn(help='"Dataset ID of the table.\\n\\nAllowed value: The Google Cloud resource name of a `BigQueryDataset` resource (format: `projects/{{project}}/datasets/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
              withExternal(external): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { datasetRef+: { external: external } } } } } } },
              '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { datasetRef+: { name: name } } } } } } },
              '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
              withNamespace(namespace): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { datasetRef+: { namespace: namespace } } } } } } },
            },
            '#projectRef':: d.obj(help=''),
            projectRef: {
              '#withExternal':: d.fn(help='"The Google Cloud Platform project ID of the project containing the table. If omitted, project ID is inferred from the API call.\\n\\nAllowed value: The Google Cloud resource name of a `Project` resource (format: `projects/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
              withExternal(external): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { projectRef+: { external: external } } } } } } },
              '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { projectRef+: { name: name } } } } } } },
              '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
              withNamespace(namespace): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { projectRef+: { namespace: namespace } } } } } } },
            },
            '#tableRef':: d.obj(help=''),
            tableRef: {
              '#withExternal':: d.fn(help='"Name of the table.\\n\\nAllowed value: The Google Cloud resource name of a `BigQueryTable` resource (format: `projects/{{project}}/datasets/{{dataset_id}}/tables/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
              withExternal(external): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { tableRef+: { external: external } } } } } } },
              '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { tableRef+: { name: name } } } } } } },
              '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
              withNamespace(namespace): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { tableReference+: { tableRef+: { namespace: namespace } } } } } } },
            },
          },
          '#withExcludedFields':: d.fn(help='"References to fields excluded from scanning. This allows you to skip inspection of entire columns which you know have no findings."', args=[d.arg(name='excludedFields', type=d.T.array)]),
          withExcludedFields(excludedFields): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { excludedFields: if std.isArray(v=excludedFields) then excludedFields else [excludedFields] } } } } },
          '#withExcludedFieldsMixin':: d.fn(help='"References to fields excluded from scanning. This allows you to skip inspection of entire columns which you know have no findings."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='excludedFields', type=d.T.array)]),
          withExcludedFieldsMixin(excludedFields): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { excludedFields+: if std.isArray(v=excludedFields) then excludedFields else [excludedFields] } } } } },
          '#withIdentifyingFields':: d.fn(help='"Table fields that may uniquely identify a row within the table. When `actions.saveFindings.outputConfig.table` is specified, the values of columns specified here are available in the output table under `location.content_locations.record_location.record_key.id_values`. Nested fields such as `person.birthdate.year` are allowed."', args=[d.arg(name='identifyingFields', type=d.T.array)]),
          withIdentifyingFields(identifyingFields): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { identifyingFields: if std.isArray(v=identifyingFields) then identifyingFields else [identifyingFields] } } } } },
          '#withIdentifyingFieldsMixin':: d.fn(help='"Table fields that may uniquely identify a row within the table. When `actions.saveFindings.outputConfig.table` is specified, the values of columns specified here are available in the output table under `location.content_locations.record_location.record_key.id_values`. Nested fields such as `person.birthdate.year` are allowed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identifyingFields', type=d.T.array)]),
          withIdentifyingFieldsMixin(identifyingFields): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { identifyingFields+: if std.isArray(v=identifyingFields) then identifyingFields else [identifyingFields] } } } } },
          '#withIncludedFields':: d.fn(help='"Limit scanning only to these fields."', args=[d.arg(name='includedFields', type=d.T.array)]),
          withIncludedFields(includedFields): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { includedFields: if std.isArray(v=includedFields) then includedFields else [includedFields] } } } } },
          '#withIncludedFieldsMixin':: d.fn(help='"Limit scanning only to these fields."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='includedFields', type=d.T.array)]),
          withIncludedFieldsMixin(includedFields): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { includedFields+: if std.isArray(v=includedFields) then includedFields else [includedFields] } } } } },
          '#withRowsLimit':: d.fn(help='"Max number of rows to scan. If the table has more rows than this value, the rest of the rows are omitted. If not set, or if set to 0, all rows will be scanned. Only one of rows_limit and rows_limit_percent can be specified. Cannot be used in conjunction with TimespanConfig."', args=[d.arg(name='rowsLimit', type=d.T.integer)]),
          withRowsLimit(rowsLimit): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { rowsLimit: rowsLimit } } } } },
          '#withRowsLimitPercent':: d.fn(help='"Max percentage of rows to scan. The rest are omitted. The number of rows scanned is rounded down. Must be between 0 and 100, inclusively. Both 0 and 100 means no limit. Defaults to 0. Only one of rows_limit and rows_limit_percent can be specified. Cannot be used in conjunction with TimespanConfig."', args=[d.arg(name='rowsLimitPercent', type=d.T.integer)]),
          withRowsLimitPercent(rowsLimitPercent): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { rowsLimitPercent: rowsLimitPercent } } } } },
          '#withSampleMethod':: d.fn(help='" Possible values: SAMPLE_METHOD_UNSPECIFIED, TOP, RANDOM_START"', args=[d.arg(name='sampleMethod', type=d.T.string)]),
          withSampleMethod(sampleMethod): { spec+: { inspectJob+: { storageConfig+: { bigQueryOptions+: { sampleMethod: sampleMethod } } } } },
        },
        '#cloudStorageOptions':: d.obj(help='"Google Cloud Storage options."'),
        cloudStorageOptions: {
          '#fileSet':: d.obj(help='"The set of one or more files to scan."'),
          fileSet: {
            '#regexFileSet':: d.obj(help='"The regex-filtered set of files to scan. Exactly one of `url` or `regex_file_set` must be set."'),
            regexFileSet: {
              '#bucketRef':: d.obj(help=''),
              bucketRef: {
                '#withExternal':: d.fn(help='"The name of a Cloud Storage bucket. Required.\\n\\nAllowed value: The Google Cloud resource name of a `StorageBucket` resource (format: `{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
                withExternal(external): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { regexFileSet+: { bucketRef+: { external: external } } } } } } } },
                '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { regexFileSet+: { bucketRef+: { name: name } } } } } } } },
                '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { regexFileSet+: { bucketRef+: { namespace: namespace } } } } } } } },
              },
              '#withExcludeRegex':: d.fn(help='"A list of regular expressions matching file paths to exclude. All files in the bucket that match at least one of these regular expressions will be excluded from the scan. Regular expressions use RE2 [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found under the google/re2 repository on GitHub."', args=[d.arg(name='excludeRegex', type=d.T.array)]),
              withExcludeRegex(excludeRegex): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { regexFileSet+: { excludeRegex: if std.isArray(v=excludeRegex) then excludeRegex else [excludeRegex] } } } } } } },
              '#withExcludeRegexMixin':: d.fn(help='"A list of regular expressions matching file paths to exclude. All files in the bucket that match at least one of these regular expressions will be excluded from the scan. Regular expressions use RE2 [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found under the google/re2 repository on GitHub."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='excludeRegex', type=d.T.array)]),
              withExcludeRegexMixin(excludeRegex): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { regexFileSet+: { excludeRegex+: if std.isArray(v=excludeRegex) then excludeRegex else [excludeRegex] } } } } } } },
              '#withIncludeRegex':: d.fn(help='"A list of regular expressions matching file paths to include. All files in the bucket that match at least one of these regular expressions will be included in the set of files, except for those that also match an item in `exclude_regex`. Leaving this field empty will match all files by default (this is equivalent to including `.*` in the list). Regular expressions use RE2 [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found under the google/re2 repository on GitHub."', args=[d.arg(name='includeRegex', type=d.T.array)]),
              withIncludeRegex(includeRegex): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { regexFileSet+: { includeRegex: if std.isArray(v=includeRegex) then includeRegex else [includeRegex] } } } } } } },
              '#withIncludeRegexMixin':: d.fn(help='"A list of regular expressions matching file paths to include. All files in the bucket that match at least one of these regular expressions will be included in the set of files, except for those that also match an item in `exclude_regex`. Leaving this field empty will match all files by default (this is equivalent to including `.*` in the list). Regular expressions use RE2 [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found under the google/re2 repository on GitHub."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='includeRegex', type=d.T.array)]),
              withIncludeRegexMixin(includeRegex): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { regexFileSet+: { includeRegex+: if std.isArray(v=includeRegex) then includeRegex else [includeRegex] } } } } } } },
            },
            '#withUrl':: d.fn(help='"The Cloud Storage url of the file(s) to scan, in the format `gs:///`. Trailing wildcard in the path is allowed. If the url ends in a trailing slash, the bucket or directory represented by the url will be scanned non-recursively (content in sub-directories will not be scanned). This means that `gs://mybucket/` is equivalent to `gs://mybucket/*`, and `gs://mybucket/directory/` is equivalent to `gs://mybucket/directory/*`. Exactly one of `url` or `regex_file_set` must be set."', args=[d.arg(name='url', type=d.T.string)]),
            withUrl(url): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileSet+: { url: url } } } } } },
          },
          '#withBytesLimitPerFile':: d.fn(help="\"Max number of bytes to scan from a file. If a scanned file's size is bigger than this value then the rest of the bytes are omitted. Only one of bytes_limit_per_file and bytes_limit_per_file_percent can be specified. Cannot be set if de-identification is requested.\"", args=[d.arg(name='bytesLimitPerFile', type=d.T.integer)]),
          withBytesLimitPerFile(bytesLimitPerFile): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { bytesLimitPerFile: bytesLimitPerFile } } } } },
          '#withBytesLimitPerFilePercent':: d.fn(help='"Max percentage of bytes to scan from a file. The rest are omitted. The number of bytes scanned is rounded down. Must be between 0 and 100, inclusively. Both 0 and 100 means no limit. Defaults to 0. Only one of bytes_limit_per_file and bytes_limit_per_file_percent can be specified. Cannot be set if de-identification is requested."', args=[d.arg(name='bytesLimitPerFilePercent', type=d.T.integer)]),
          withBytesLimitPerFilePercent(bytesLimitPerFilePercent): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { bytesLimitPerFilePercent: bytesLimitPerFilePercent } } } } },
          '#withFileTypes':: d.fn(help="\"List of file type groups to include in the scan. If empty, all files are scanned and available data format processors are applied. In addition, the binary content of the selected files is always scanned as well. Images are scanned only as binary if the specified region does not support image inspection and no file_types were specified. Image inspection is restricted to 'global', 'us', 'asia', and 'europe'.\"", args=[d.arg(name='fileTypes', type=d.T.array)]),
          withFileTypes(fileTypes): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileTypes: if std.isArray(v=fileTypes) then fileTypes else [fileTypes] } } } } },
          '#withFileTypesMixin':: d.fn(help="\"List of file type groups to include in the scan. If empty, all files are scanned and available data format processors are applied. In addition, the binary content of the selected files is always scanned as well. Images are scanned only as binary if the specified region does not support image inspection and no file_types were specified. Image inspection is restricted to 'global', 'us', 'asia', and 'europe'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='fileTypes', type=d.T.array)]),
          withFileTypesMixin(fileTypes): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { fileTypes+: if std.isArray(v=fileTypes) then fileTypes else [fileTypes] } } } } },
          '#withFilesLimitPercent':: d.fn(help='"Limits the number of files to scan to this percentage of the input FileSet. Number of files scanned is rounded down. Must be between 0 and 100, inclusively. Both 0 and 100 means no limit. Defaults to 0."', args=[d.arg(name='filesLimitPercent', type=d.T.integer)]),
          withFilesLimitPercent(filesLimitPercent): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { filesLimitPercent: filesLimitPercent } } } } },
          '#withSampleMethod':: d.fn(help='" Possible values: SAMPLE_METHOD_UNSPECIFIED, TOP, RANDOM_START"', args=[d.arg(name='sampleMethod', type=d.T.string)]),
          withSampleMethod(sampleMethod): { spec+: { inspectJob+: { storageConfig+: { cloudStorageOptions+: { sampleMethod: sampleMethod } } } } },
        },
        '#datastoreOptions':: d.obj(help='"Google Cloud Datastore options."'),
        datastoreOptions: {
          '#kind':: d.obj(help='"The kind to process."'),
          kind: {
            '#withName':: d.fn(help='"The name of the kind."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { inspectJob+: { storageConfig+: { datastoreOptions+: { kind+: { name: name } } } } } },
          },
          '#partitionId':: d.obj(help='"A partition ID identifies a grouping of entities. The grouping is always by project namespace ID may be empty."'),
          partitionId: {
            '#projectRef':: d.obj(help=''),
            projectRef: {
              '#withExternal':: d.fn(help='"The ID of the project to which the entities belong.\\n\\nAllowed value: The Google Cloud resource name of a `Project` resource (format: `projects/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
              withExternal(external): { spec+: { inspectJob+: { storageConfig+: { datastoreOptions+: { partitionId+: { projectRef+: { external: external } } } } } } },
              '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { spec+: { inspectJob+: { storageConfig+: { datastoreOptions+: { partitionId+: { projectRef+: { name: name } } } } } } },
              '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
              withNamespace(namespace): { spec+: { inspectJob+: { storageConfig+: { datastoreOptions+: { partitionId+: { projectRef+: { namespace: namespace } } } } } } },
            },
            '#withNamespaceId':: d.fn(help='"If not empty, the ID of the namespace to which the entities belong."', args=[d.arg(name='namespaceId', type=d.T.string)]),
            withNamespaceId(namespaceId): { spec+: { inspectJob+: { storageConfig+: { datastoreOptions+: { partitionId+: { namespaceId: namespaceId } } } } } },
          },
        },
        '#hybridOptions':: d.obj(help='"Hybrid inspection options."'),
        hybridOptions: {
          '#tableOptions':: d.obj(help='"If the container is a table, additional information to make findings meaningful such as the columns that are primary keys."'),
          tableOptions: {
            '#identifyingFields':: d.obj(help="\"The columns that are the primary keys for table objects included in ContentItem. A copy of this cell's value will stored alongside alongside each finding so that the finding can be traced to the specific row it came from. No more than 3 may be provided.\""),
            identifyingFields: {
              '#withName':: d.fn(help='"Name describing the field."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#withIdentifyingFields':: d.fn(help="\"The columns that are the primary keys for table objects included in ContentItem. A copy of this cell's value will stored alongside alongside each finding so that the finding can be traced to the specific row it came from. No more than 3 may be provided.\"", args=[d.arg(name='identifyingFields', type=d.T.array)]),
            withIdentifyingFields(identifyingFields): { spec+: { inspectJob+: { storageConfig+: { hybridOptions+: { tableOptions+: { identifyingFields: if std.isArray(v=identifyingFields) then identifyingFields else [identifyingFields] } } } } } },
            '#withIdentifyingFieldsMixin':: d.fn(help="\"The columns that are the primary keys for table objects included in ContentItem. A copy of this cell's value will stored alongside alongside each finding so that the finding can be traced to the specific row it came from. No more than 3 may be provided.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='identifyingFields', type=d.T.array)]),
            withIdentifyingFieldsMixin(identifyingFields): { spec+: { inspectJob+: { storageConfig+: { hybridOptions+: { tableOptions+: { identifyingFields+: if std.isArray(v=identifyingFields) then identifyingFields else [identifyingFields] } } } } } },
          },
          '#withDescription':: d.fn(help='"A short description of where the data is coming from. Will be stored once in the job. 256 max length."', args=[d.arg(name='description', type=d.T.string)]),
          withDescription(description): { spec+: { inspectJob+: { storageConfig+: { hybridOptions+: { description: description } } } } },
          '#withLabels':: d.fn(help='"To organize findings, these labels will be added to each finding. Label keys must be between 1 and 63 characters long and must conform to the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`. Label values must be between 0 and 63 characters long and must conform to the regular expression `([a-z]([-a-z0-9]*[a-z0-9])?)?`. No more than 10 labels can be associated with a given finding. Examples: * `\\"environment\\" : \\"production\\"` * `\\"pipeline\\" : \\"etl\\"`"', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { inspectJob+: { storageConfig+: { hybridOptions+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='"To organize findings, these labels will be added to each finding. Label keys must be between 1 and 63 characters long and must conform to the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`. Label values must be between 0 and 63 characters long and must conform to the regular expression `([a-z]([-a-z0-9]*[a-z0-9])?)?`. No more than 10 labels can be associated with a given finding. Examples: * `\\"environment\\" : \\"production\\"` * `\\"pipeline\\" : \\"etl\\"`"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { inspectJob+: { storageConfig+: { hybridOptions+: { labels+: labels } } } } },
          '#withRequiredFindingLabelKeys':: d.fn(help="\"These are labels that each inspection request must include within their 'finding_labels' map. Request may contain others, but any missing one of these will be rejected. Label keys must be between 1 and 63 characters long and must conform to the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`. No more than 10 keys can be required.\"", args=[d.arg(name='requiredFindingLabelKeys', type=d.T.array)]),
          withRequiredFindingLabelKeys(requiredFindingLabelKeys): { spec+: { inspectJob+: { storageConfig+: { hybridOptions+: { requiredFindingLabelKeys: if std.isArray(v=requiredFindingLabelKeys) then requiredFindingLabelKeys else [requiredFindingLabelKeys] } } } } },
          '#withRequiredFindingLabelKeysMixin':: d.fn(help="\"These are labels that each inspection request must include within their 'finding_labels' map. Request may contain others, but any missing one of these will be rejected. Label keys must be between 1 and 63 characters long and must conform to the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`. No more than 10 keys can be required.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='requiredFindingLabelKeys', type=d.T.array)]),
          withRequiredFindingLabelKeysMixin(requiredFindingLabelKeys): { spec+: { inspectJob+: { storageConfig+: { hybridOptions+: { requiredFindingLabelKeys+: if std.isArray(v=requiredFindingLabelKeys) then requiredFindingLabelKeys else [requiredFindingLabelKeys] } } } } },
        },
        '#timespanConfig':: d.obj(help=''),
        timespanConfig: {
          '#timestampField':: d.obj(help='"Specification of the field containing the timestamp of scanned items. Used for data sources like Datastore and BigQuery. For BigQuery: If this value is not specified and the table was modified between the given start and end times, the entire table will be scanned. If this value is specified, then rows are filtered based on the given start and end times. Rows with a `NULL` value in the provided BigQuery column are skipped. Valid data types of the provided BigQuery column are: `INTEGER`, `DATE`, `TIMESTAMP`, and `DATETIME`. For Datastore: If this value is specified, then entities are filtered based on the given start and end times. If an entity does not contain the provided timestamp property or contains empty or invalid values, then it is included. Valid data types of the provided timestamp property are: `TIMESTAMP`."'),
          timestampField: {
            '#withName':: d.fn(help='"Name describing the field."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { inspectJob+: { storageConfig+: { timespanConfig+: { timestampField+: { name: name } } } } } },
          },
          '#withEnableAutoPopulationOfTimespanConfig':: d.fn(help='"When the job is started by a JobTrigger we will automatically figure out a valid start_time to avoid scanning files that have not been modified since the last time the JobTrigger executed. This will be based on the time of the execution of the last run of the JobTrigger."', args=[d.arg(name='enableAutoPopulationOfTimespanConfig', type=d.T.boolean)]),
          withEnableAutoPopulationOfTimespanConfig(enableAutoPopulationOfTimespanConfig): { spec+: { inspectJob+: { storageConfig+: { timespanConfig+: { enableAutoPopulationOfTimespanConfig: enableAutoPopulationOfTimespanConfig } } } } },
          '#withEndTime':: d.fn(help='"Exclude files, tables, or rows newer than this value. If not set, no upper time limit is applied."', args=[d.arg(name='endTime', type=d.T.string)]),
          withEndTime(endTime): { spec+: { inspectJob+: { storageConfig+: { timespanConfig+: { endTime: endTime } } } } },
          '#withStartTime':: d.fn(help='"Exclude files, tables, or rows older than this value. If not set, no lower time limit is applied."', args=[d.arg(name='startTime', type=d.T.string)]),
          withStartTime(startTime): { spec+: { inspectJob+: { storageConfig+: { timespanConfig+: { startTime: startTime } } } } },
        },
      },
      '#withActions':: d.fn(help='"Actions to execute at the completion of the job."', args=[d.arg(name='actions', type=d.T.array)]),
      withActions(actions): { spec+: { inspectJob+: { actions: if std.isArray(v=actions) then actions else [actions] } } },
      '#withActionsMixin':: d.fn(help='"Actions to execute at the completion of the job."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='actions', type=d.T.array)]),
      withActionsMixin(actions): { spec+: { inspectJob+: { actions+: if std.isArray(v=actions) then actions else [actions] } } },
    },
    '#projectRef':: d.obj(help='"Immutable. The Project that this resource belongs to. Only one of [projectRef] may be specified."'),
    projectRef: {
      '#withExternal':: d.fn(help='"Allowed value: The Google Cloud resource name of a `Project` resource (format: `projects/{{name}}`)."', args=[d.arg(name='external', type=d.T.string)]),
      withExternal(external): { spec+: { projectRef+: { external: external } } },
      '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { projectRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { projectRef+: { namespace: namespace } } },
    },
    '#triggers':: d.obj(help="\"A list of triggers which will be OR'ed together. Only one in the list needs to trigger for a job to be started. The list may contain only a single Schedule trigger and must have at least one object.\""),
    triggers: {
      '#schedule':: d.obj(help='"Create a job on a repeating basis based on the elapse of time."'),
      schedule: {
        '#withRecurrencePeriodDuration':: d.fn(help='"With this option a job is started a regular periodic basis. For example: every day (86400 seconds). A scheduled start time will be skipped if the previous execution has not ended when its scheduled time occurs. This value must be set to a time duration greater than or equal to 1 day and can be no longer than 60 days."', args=[d.arg(name='recurrencePeriodDuration', type=d.T.string)]),
        withRecurrencePeriodDuration(recurrencePeriodDuration): { schedule+: { recurrencePeriodDuration: recurrencePeriodDuration } },
      },
      '#withManual':: d.fn(help='"For use with hybrid jobs. Jobs must be manually created and finished."', args=[d.arg(name='manual', type=d.T.object)]),
      withManual(manual): { manual: manual },
      '#withManualMixin':: d.fn(help='"For use with hybrid jobs. Jobs must be manually created and finished."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='manual', type=d.T.object)]),
      withManualMixin(manual): { manual+: manual },
    },
    '#withDescription':: d.fn(help='"User provided description (max 256 chars)"', args=[d.arg(name='description', type=d.T.string)]),
    withDescription(description): { spec+: { description: description } },
    '#withDisplayName':: d.fn(help='"Display name (max 100 chars)"', args=[d.arg(name='displayName', type=d.T.string)]),
    withDisplayName(displayName): { spec+: { displayName: displayName } },
    '#withLocation':: d.fn(help='"Immutable. The location of the resource"', args=[d.arg(name='location', type=d.T.string)]),
    withLocation(location): { spec+: { location: location } },
    '#withResourceID':: d.fn(help='"Immutable. Optional. The service-generated name of the resource. Used for acquisition only. Leave unset to create a new resource."', args=[d.arg(name='resourceID', type=d.T.string)]),
    withResourceID(resourceID): { spec+: { resourceID: resourceID } },
    '#withStatus':: d.fn(help='"Immutable. Required. A status for this trigger. Possible values: STATUS_UNSPECIFIED, HEALTHY, PAUSED, CANCELLED"', args=[d.arg(name='status', type=d.T.string)]),
    withStatus(status): { spec+: { status: status } },
    '#withTriggers':: d.fn(help="\"A list of triggers which will be OR'ed together. Only one in the list needs to trigger for a job to be started. The list may contain only a single Schedule trigger and must have at least one object.\"", args=[d.arg(name='triggers', type=d.T.array)]),
    withTriggers(triggers): { spec+: { triggers: if std.isArray(v=triggers) then triggers else [triggers] } },
    '#withTriggersMixin':: d.fn(help="\"A list of triggers which will be OR'ed together. Only one in the list needs to trigger for a job to be started. The list may contain only a single Schedule trigger and must have at least one object.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='triggers', type=d.T.array)]),
    withTriggersMixin(triggers): { spec+: { triggers+: if std.isArray(v=triggers) then triggers else [triggers] } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
