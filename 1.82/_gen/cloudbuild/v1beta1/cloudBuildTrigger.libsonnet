{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='cloudBuildTrigger', url='', help=''),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of CloudBuildTrigger', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'cloudbuild.cnrm.cloud.google.com/v1beta1',
    kind: 'CloudBuildTrigger',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help=''),
  spec: {
    '#build':: d.obj(help='"Contents of the build template. Either a filename or build template must be provided."'),
    build: {
      '#artifacts':: d.obj(help='"Artifacts produced by the build that should be uploaded upon successful completion of all build steps."'),
      artifacts: {
        '#objects':: d.obj(help="\"A list of objects to be uploaded to Cloud Storage upon successful completion of all build steps.\\n\\nFiles in the workspace matching specified paths globs will be uploaded to the\\nCloud Storage location using the builder service account's credentials.\\n\\nThe location and generation of the uploaded objects will be stored in the Build resource's results field.\\n\\nIf any objects fail to be pushed, the build is marked FAILURE.\""),
        objects: {
          '#timing':: d.obj(help='"Output only. Stores timing information for pushing all artifact objects."'),
          timing: {
            '#withEndTime':: d.fn(help='"End of time span.\\n\\nA timestamp in RFC3339 UTC \\"Zulu\\" format, with nanosecond resolution and up to\\nnine fractional digits. Examples: \\"2014-10-02T15:01:23Z\\" and \\"2014-10-02T15:01:23.045123456Z\\"."', args=[d.arg(name='endTime', type=d.T.string)]),
            withEndTime(endTime): { endTime: endTime },
            '#withStartTime':: d.fn(help='"Start of time span.\\n\\nA timestamp in RFC3339 UTC \\"Zulu\\" format, with nanosecond resolution and up to\\nnine fractional digits. Examples: \\"2014-10-02T15:01:23Z\\" and \\"2014-10-02T15:01:23.045123456Z\\"."', args=[d.arg(name='startTime', type=d.T.string)]),
            withStartTime(startTime): { startTime: startTime },
          },
          '#withLocation':: d.fn(help='"Cloud Storage bucket and optional object path, in the form \\"gs://bucket/path/to/somewhere/\\".\\n\\nFiles in the workspace matching any path pattern will be uploaded to Cloud Storage with\\nthis location as a prefix."', args=[d.arg(name='location', type=d.T.string)]),
          withLocation(location): { spec+: { build+: { artifacts+: { objects+: { location: location } } } } },
          '#withPaths':: d.fn(help="\"Path globs used to match files in the build's workspace.\"", args=[d.arg(name='paths', type=d.T.array)]),
          withPaths(paths): { spec+: { build+: { artifacts+: { objects+: { paths: if std.isArray(v=paths) then paths else [paths] } } } } },
          '#withPathsMixin':: d.fn(help="\"Path globs used to match files in the build's workspace.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='paths', type=d.T.array)]),
          withPathsMixin(paths): { spec+: { build+: { artifacts+: { objects+: { paths+: if std.isArray(v=paths) then paths else [paths] } } } } },
          '#withTiming':: d.fn(help='"Output only. Stores timing information for pushing all artifact objects."', args=[d.arg(name='timing', type=d.T.array)]),
          withTiming(timing): { spec+: { build+: { artifacts+: { objects+: { timing: if std.isArray(v=timing) then timing else [timing] } } } } },
          '#withTimingMixin':: d.fn(help='"Output only. Stores timing information for pushing all artifact objects."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='timing', type=d.T.array)]),
          withTimingMixin(timing): { spec+: { build+: { artifacts+: { objects+: { timing+: if std.isArray(v=timing) then timing else [timing] } } } } },
        },
        '#withImages':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps.\\n\\nThe images will be pushed using the builder service account's credentials.\\n\\nThe digests of the pushed images will be stored in the Build resource's results field.\\n\\nIf any of the images fail to be pushed, the build is marked FAILURE.\"", args=[d.arg(name='images', type=d.T.array)]),
        withImages(images): { spec+: { build+: { artifacts+: { images: if std.isArray(v=images) then images else [images] } } } },
        '#withImagesMixin':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps.\\n\\nThe images will be pushed using the builder service account's credentials.\\n\\nThe digests of the pushed images will be stored in the Build resource's results field.\\n\\nIf any of the images fail to be pushed, the build is marked FAILURE.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='images', type=d.T.array)]),
        withImagesMixin(images): { spec+: { build+: { artifacts+: { images+: if std.isArray(v=images) then images else [images] } } } },
      },
      '#availableSecrets':: d.obj(help='"Secrets and secret environment variables."'),
      availableSecrets: {
        '#secretManager':: d.obj(help='"Pairs a secret environment variable with a SecretVersion in Secret Manager."'),
        secretManager: {
          '#versionRef':: d.obj(help=''),
          versionRef: {
            '#withExternal':: d.fn(help='"Allowed value: The `name` field of a `SecretManagerSecretVersion` resource."', args=[d.arg(name='external', type=d.T.string)]),
            withExternal(external): { versionRef+: { external: external } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { versionRef+: { name: name } },
            '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
            withNamespace(namespace): { versionRef+: { namespace: namespace } },
          },
          '#withEnv':: d.fn(help="\"Environment variable name to associate with the secret. Secret environment\\nvariables must be unique across all of a build's secrets, and must be used\\nby at least one build step.\"", args=[d.arg(name='env', type=d.T.string)]),
          withEnv(env): { env: env },
        },
        '#withSecretManager':: d.fn(help='"Pairs a secret environment variable with a SecretVersion in Secret Manager."', args=[d.arg(name='secretManager', type=d.T.array)]),
        withSecretManager(secretManager): { spec+: { build+: { availableSecrets+: { secretManager: if std.isArray(v=secretManager) then secretManager else [secretManager] } } } },
        '#withSecretManagerMixin':: d.fn(help='"Pairs a secret environment variable with a SecretVersion in Secret Manager."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secretManager', type=d.T.array)]),
        withSecretManagerMixin(secretManager): { spec+: { build+: { availableSecrets+: { secretManager+: if std.isArray(v=secretManager) then secretManager else [secretManager] } } } },
      },
      '#logsBucketRef':: d.obj(help='"Google Cloud Storage bucket where logs should be written. Logs file\\nnames will be of the format ${logsBucket}/log-${build_id}.txt."'),
      logsBucketRef: {
        '#withExternal':: d.fn(help='"Allowed value: The `url` field of a `StorageBucket` resource."', args=[d.arg(name='external', type=d.T.string)]),
        withExternal(external): { spec+: { build+: { logsBucketRef+: { external: external } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { build+: { logsBucketRef+: { name: name } } } },
        '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { build+: { logsBucketRef+: { namespace: namespace } } } },
      },
      '#options':: d.obj(help='"Special options for this build."'),
      options: {
        '#volumes':: d.obj(help='"Global list of volumes to mount for ALL build steps\\n\\nEach volume is created as an empty volume prior to starting the build process.\\nUpon completion of the build, volumes and their contents are discarded. Global\\nvolume names and paths cannot conflict with the volumes defined a build step.\\n\\nUsing a global volume in a build with only one step is not valid as it is indicative\\nof a build request with an incorrect configuration."'),
        volumes: {
          '#withName':: d.fn(help='"Name of the volume to mount.\\n\\nVolume names must be unique per build step and must be valid names for Docker volumes.\\nEach named volume must be used by at least two build steps."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withPath':: d.fn(help='"Path at which to mount the volume.\\n\\nPaths must be absolute and cannot conflict with other volume paths on the same\\nbuild step or with certain reserved volume paths."', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { path: path },
        },
        '#withDiskSizeGb':: d.fn(help='"Requested disk size for the VM that runs the build. Note that this is NOT \\"disk free\\";\\nsome of the space will be used by the operating system and build utilities.\\nAlso note that this is the minimum disk size that will be allocated for the build --\\nthe build may run with a larger disk than requested. At present, the maximum disk size\\nis 1000GB; builds that request more than the maximum are rejected with an error."', args=[d.arg(name='diskSizeGb', type=d.T.integer)]),
        withDiskSizeGb(diskSizeGb): { spec+: { build+: { options+: { diskSizeGb: diskSizeGb } } } },
        '#withDynamicSubstitutions':: d.fn(help='"Option to specify whether or not to apply bash style string operations to the substitutions.\\n\\nNOTE this is always enabled for triggered builds and cannot be overridden in the build configuration file."', args=[d.arg(name='dynamicSubstitutions', type=d.T.boolean)]),
        withDynamicSubstitutions(dynamicSubstitutions): { spec+: { build+: { options+: { dynamicSubstitutions: dynamicSubstitutions } } } },
        '#withEnv':: d.fn(help='"A list of global environment variable definitions that will exist for all build steps\\nin this build. If a variable is defined in both globally and in a build step,\\nthe variable will use the build step value.\\n\\nThe elements are of the form \\"KEY=VALUE\\" for the environment variable \\"KEY\\" being given the value \\"VALUE\\"."', args=[d.arg(name='env', type=d.T.array)]),
        withEnv(env): { spec+: { build+: { options+: { env: if std.isArray(v=env) then env else [env] } } } },
        '#withEnvMixin':: d.fn(help='"A list of global environment variable definitions that will exist for all build steps\\nin this build. If a variable is defined in both globally and in a build step,\\nthe variable will use the build step value.\\n\\nThe elements are of the form \\"KEY=VALUE\\" for the environment variable \\"KEY\\" being given the value \\"VALUE\\"."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
        withEnvMixin(env): { spec+: { build+: { options+: { env+: if std.isArray(v=env) then env else [env] } } } },
        '#withLogStreamingOption':: d.fn(help='"Option to define build log streaming behavior to Google Cloud Storage. Possible values: [\\"STREAM_DEFAULT\\", \\"STREAM_ON\\", \\"STREAM_OFF\\"]."', args=[d.arg(name='logStreamingOption', type=d.T.string)]),
        withLogStreamingOption(logStreamingOption): { spec+: { build+: { options+: { logStreamingOption: logStreamingOption } } } },
        '#withLogging':: d.fn(help='"Option to specify the logging mode, which determines if and where build logs are stored. Possible values: [\\"LOGGING_UNSPECIFIED\\", \\"LEGACY\\", \\"GCS_ONLY\\", \\"STACKDRIVER_ONLY\\", \\"NONE\\"]."', args=[d.arg(name='logging', type=d.T.string)]),
        withLogging(logging): { spec+: { build+: { options+: { logging: logging } } } },
        '#withMachineType':: d.fn(help='"Compute Engine machine type on which to run the build. Possible values: [\\"UNSPECIFIED\\", \\"N1_HIGHCPU_8\\", \\"N1_HIGHCPU_32\\", \\"E2_HIGHCPU_8\\", \\"E2_HIGHCPU_32\\"]."', args=[d.arg(name='machineType', type=d.T.string)]),
        withMachineType(machineType): { spec+: { build+: { options+: { machineType: machineType } } } },
        '#withRequestedVerifyOption':: d.fn(help='"Requested verifiability options. Possible values: [\\"NOT_VERIFIED\\", \\"VERIFIED\\"]."', args=[d.arg(name='requestedVerifyOption', type=d.T.string)]),
        withRequestedVerifyOption(requestedVerifyOption): { spec+: { build+: { options+: { requestedVerifyOption: requestedVerifyOption } } } },
        '#withSecretEnv':: d.fn(help="\"A list of global environment variables, which are encrypted using a Cloud Key Management\\nService crypto key. These values must be specified in the build's Secret. These variables\\nwill be available to all build steps in this build.\"", args=[d.arg(name='secretEnv', type=d.T.array)]),
        withSecretEnv(secretEnv): { spec+: { build+: { options+: { secretEnv: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] } } } },
        '#withSecretEnvMixin':: d.fn(help="\"A list of global environment variables, which are encrypted using a Cloud Key Management\\nService crypto key. These values must be specified in the build's Secret. These variables\\nwill be available to all build steps in this build.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='secretEnv', type=d.T.array)]),
        withSecretEnvMixin(secretEnv): { spec+: { build+: { options+: { secretEnv+: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] } } } },
        '#withSourceProvenanceHash':: d.fn(help='"Requested hash for SourceProvenance. Possible values: [\\"NONE\\", \\"SHA256\\", \\"MD5\\"]."', args=[d.arg(name='sourceProvenanceHash', type=d.T.array)]),
        withSourceProvenanceHash(sourceProvenanceHash): { spec+: { build+: { options+: { sourceProvenanceHash: if std.isArray(v=sourceProvenanceHash) then sourceProvenanceHash else [sourceProvenanceHash] } } } },
        '#withSourceProvenanceHashMixin':: d.fn(help='"Requested hash for SourceProvenance. Possible values: [\\"NONE\\", \\"SHA256\\", \\"MD5\\"]."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sourceProvenanceHash', type=d.T.array)]),
        withSourceProvenanceHashMixin(sourceProvenanceHash): { spec+: { build+: { options+: { sourceProvenanceHash+: if std.isArray(v=sourceProvenanceHash) then sourceProvenanceHash else [sourceProvenanceHash] } } } },
        '#withSubstitutionOption':: d.fn(help='"Option to specify behavior when there is an error in the substitution checks.\\n\\nNOTE this is always set to ALLOW_LOOSE for triggered builds and cannot be overridden\\nin the build configuration file. Possible values: [\\"MUST_MATCH\\", \\"ALLOW_LOOSE\\"]."', args=[d.arg(name='substitutionOption', type=d.T.string)]),
        withSubstitutionOption(substitutionOption): { spec+: { build+: { options+: { substitutionOption: substitutionOption } } } },
        '#withVolumes':: d.fn(help='"Global list of volumes to mount for ALL build steps\\n\\nEach volume is created as an empty volume prior to starting the build process.\\nUpon completion of the build, volumes and their contents are discarded. Global\\nvolume names and paths cannot conflict with the volumes defined a build step.\\n\\nUsing a global volume in a build with only one step is not valid as it is indicative\\nof a build request with an incorrect configuration."', args=[d.arg(name='volumes', type=d.T.array)]),
        withVolumes(volumes): { spec+: { build+: { options+: { volumes: if std.isArray(v=volumes) then volumes else [volumes] } } } },
        '#withVolumesMixin':: d.fn(help='"Global list of volumes to mount for ALL build steps\\n\\nEach volume is created as an empty volume prior to starting the build process.\\nUpon completion of the build, volumes and their contents are discarded. Global\\nvolume names and paths cannot conflict with the volumes defined a build step.\\n\\nUsing a global volume in a build with only one step is not valid as it is indicative\\nof a build request with an incorrect configuration."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
        withVolumesMixin(volumes): { spec+: { build+: { options+: { volumes+: if std.isArray(v=volumes) then volumes else [volumes] } } } },
        '#withWorkerPool':: d.fn(help='"Option to specify a WorkerPool for the build. Format projects/{project}/workerPools/{workerPool}\\n\\nThis field is experimental."', args=[d.arg(name='workerPool', type=d.T.string)]),
        withWorkerPool(workerPool): { spec+: { build+: { options+: { workerPool: workerPool } } } },
      },
      '#secret':: d.obj(help='"Secrets to decrypt using Cloud Key Management Service."'),
      secret: {
        '#kmsKeyRef':: d.obj(help='"KMS crypto key to use to decrypt these envs."'),
        kmsKeyRef: {
          '#withExternal':: d.fn(help='"Allowed value: The `selfLink` field of a `KMSCryptoKey` resource."', args=[d.arg(name='external', type=d.T.string)]),
          withExternal(external): { kmsKeyRef+: { external: external } },
          '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { kmsKeyRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { kmsKeyRef+: { namespace: namespace } },
        },
        '#withSecretEnv':: d.fn(help="\"Map of environment variable name to its encrypted value.\\nSecret environment variables must be unique across all of a build's secrets, \\nand must be used by at least one build step. Values can be at most 64 KB in size. \\nThere can be at most 100 secret values across all of a build's secrets.\"", args=[d.arg(name='secretEnv', type=d.T.object)]),
        withSecretEnv(secretEnv): { secretEnv: secretEnv },
        '#withSecretEnvMixin':: d.fn(help="\"Map of environment variable name to its encrypted value.\\nSecret environment variables must be unique across all of a build's secrets, \\nand must be used by at least one build step. Values can be at most 64 KB in size. \\nThere can be at most 100 secret values across all of a build's secrets.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='secretEnv', type=d.T.object)]),
        withSecretEnvMixin(secretEnv): { secretEnv+: secretEnv },
      },
      '#source':: d.obj(help="\"The location of the source files to build.\\n\\nOne of 'storageSource' or 'repoSource' must be provided.\""),
      source: {
        '#repoSource':: d.obj(help='"Location of the source in a Google Cloud Source Repository."'),
        repoSource: {
          '#repoRef':: d.obj(help='"The desired Cloud Source Repository. If omitted, \\"default\\" is\\nassumed."'),
          repoRef: {
            '#withExternal':: d.fn(help='"Allowed value: The `name` field of a `SourceRepoRepository` resource."', args=[d.arg(name='external', type=d.T.string)]),
            withExternal(external): { spec+: { build+: { source+: { repoSource+: { repoRef+: { external: external } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { build+: { source+: { repoSource+: { repoRef+: { name: name } } } } } },
            '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
            withNamespace(namespace): { spec+: { build+: { source+: { repoSource+: { repoRef+: { namespace: namespace } } } } } },
          },
          '#withBranchName':: d.fn(help='"Regex matching branches to build. Exactly one a of branch name, tag, or commit SHA must be provided.\\nThe syntax of the regular expressions accepted is the syntax accepted by RE2 and \\ndescribed at https://github.com/google/re2/wiki/Syntax."', args=[d.arg(name='branchName', type=d.T.string)]),
          withBranchName(branchName): { spec+: { build+: { source+: { repoSource+: { branchName: branchName } } } } },
          '#withCommitSha':: d.fn(help='"Explicit commit SHA to build. Exactly one a of branch name, tag, or commit SHA must be provided."', args=[d.arg(name='commitSha', type=d.T.string)]),
          withCommitSha(commitSha): { spec+: { build+: { source+: { repoSource+: { commitSha: commitSha } } } } },
          '#withDir':: d.fn(help="\"Directory, relative to the source root, in which to run the build.\\nThis must be a relative path. If a step's dir is specified and is an absolute path, \\nthis value is ignored for that step's execution.\"", args=[d.arg(name='dir', type=d.T.string)]),
          withDir(dir): { spec+: { build+: { source+: { repoSource+: { dir: dir } } } } },
          '#withInvertRegex':: d.fn(help='"Only trigger a build if the revision regex does NOT match the revision regex."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
          withInvertRegex(invertRegex): { spec+: { build+: { source+: { repoSource+: { invertRegex: invertRegex } } } } },
          '#withProjectId':: d.fn(help='"ID of the project that owns the Cloud Source Repository. \\nIf omitted, the project ID requesting the build is assumed."', args=[d.arg(name='projectId', type=d.T.string)]),
          withProjectId(projectId): { spec+: { build+: { source+: { repoSource+: { projectId: projectId } } } } },
          '#withSubstitutions':: d.fn(help='"Substitutions to use in a triggered build. Should only be used with triggers.run."', args=[d.arg(name='substitutions', type=d.T.object)]),
          withSubstitutions(substitutions): { spec+: { build+: { source+: { repoSource+: { substitutions: substitutions } } } } },
          '#withSubstitutionsMixin':: d.fn(help='"Substitutions to use in a triggered build. Should only be used with triggers.run."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='substitutions', type=d.T.object)]),
          withSubstitutionsMixin(substitutions): { spec+: { build+: { source+: { repoSource+: { substitutions+: substitutions } } } } },
          '#withTagName':: d.fn(help='"Regex matching tags to build. Exactly one a of branch name, tag, or commit SHA must be provided.\\nThe syntax of the regular expressions accepted is the syntax accepted by RE2 and \\ndescribed at https://github.com/google/re2/wiki/Syntax."', args=[d.arg(name='tagName', type=d.T.string)]),
          withTagName(tagName): { spec+: { build+: { source+: { repoSource+: { tagName: tagName } } } } },
        },
        '#storageSource':: d.obj(help='"Location of the source in an archive file in Google Cloud Storage."'),
        storageSource: {
          '#bucketRef':: d.obj(help='"Google Cloud Storage bucket containing the source."'),
          bucketRef: {
            '#withExternal':: d.fn(help='"Allowed value: The `name` field of a `StorageBucket` resource."', args=[d.arg(name='external', type=d.T.string)]),
            withExternal(external): { spec+: { build+: { source+: { storageSource+: { bucketRef+: { external: external } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { build+: { source+: { storageSource+: { bucketRef+: { name: name } } } } } },
            '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
            withNamespace(namespace): { spec+: { build+: { source+: { storageSource+: { bucketRef+: { namespace: namespace } } } } } },
          },
          '#withGeneration':: d.fn(help='"Google Cloud Storage generation for the object. \\nIf the generation is omitted, the latest generation will be used."', args=[d.arg(name='generation', type=d.T.string)]),
          withGeneration(generation): { spec+: { build+: { source+: { storageSource+: { generation: generation } } } } },
          '#withObject':: d.fn(help='"Google Cloud Storage object containing the source.\\nThis object must be a gzipped archive file (.tar.gz) containing source to build."', args=[d.arg(name='object', type=d.T.string)]),
          withObject(object): { spec+: { build+: { source+: { storageSource+: { object: object } } } } },
        },
      },
      '#step':: d.obj(help='"The operations to be performed on the workspace."'),
      step: {
        '#volumes':: d.obj(help='"List of volumes to mount into the build step.\\n\\nEach volume is created as an empty volume prior to execution of the\\nbuild step. Upon completion of the build, volumes and their contents\\nare discarded.\\n\\nUsing a named volume in only one step is not valid as it is\\nindicative of a build request with an incorrect configuration."'),
        volumes: {
          '#withName':: d.fn(help='"Name of the volume to mount.\\n\\nVolume names must be unique per build step and must be valid names for\\nDocker volumes. Each named volume must be used by at least two build steps."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withPath':: d.fn(help='"Path at which to mount the volume.\\n\\nPaths must be absolute and cannot conflict with other volume paths on\\nthe same build step or with certain reserved volume paths."', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { path: path },
        },
        '#withArgs':: d.fn(help="\"A list of arguments that will be presented to the step when it is started.\\n\\nIf the image used to run the step's container has an entrypoint, the args\\nare used as arguments to that entrypoint. If the image does not define an\\nentrypoint, the first element in args is used as the entrypoint, and the\\nremainder will be used as arguments.\"", args=[d.arg(name='args', type=d.T.array)]),
        withArgs(args): { args: if std.isArray(v=args) then args else [args] },
        '#withArgsMixin':: d.fn(help="\"A list of arguments that will be presented to the step when it is started.\\n\\nIf the image used to run the step's container has an entrypoint, the args\\nare used as arguments to that entrypoint. If the image does not define an\\nentrypoint, the first element in args is used as the entrypoint, and the\\nremainder will be used as arguments.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='args', type=d.T.array)]),
        withArgsMixin(args): { args+: if std.isArray(v=args) then args else [args] },
        '#withDir':: d.fn(help="\"Working directory to use when running this step's container.\\n\\nIf this value is a relative path, it is relative to the build's working\\ndirectory. If this value is absolute, it may be outside the build's working\\ndirectory, in which case the contents of the path may not be persisted\\nacross build step executions, unless a 'volume' for that path is specified.\\n\\nIf the build specifies a 'RepoSource' with 'dir' and a step with a\\n'dir',\\nwhich specifies an absolute path, the 'RepoSource' 'dir' is ignored\\nfor the step's execution.\"", args=[d.arg(name='dir', type=d.T.string)]),
        withDir(dir): { dir: dir },
        '#withEntrypoint':: d.fn(help="\"Entrypoint to be used instead of the build step image's\\ndefault entrypoint.\\nIf unset, the image's default entrypoint is used.\"", args=[d.arg(name='entrypoint', type=d.T.string)]),
        withEntrypoint(entrypoint): { entrypoint: entrypoint },
        '#withEnv':: d.fn(help='"A list of environment variable definitions to be used when\\nrunning a step.\\n\\nThe elements are of the form \\"KEY=VALUE\\" for the environment variable\\n\\"KEY\\" being given the value \\"VALUE\\"."', args=[d.arg(name='env', type=d.T.array)]),
        withEnv(env): { env: if std.isArray(v=env) then env else [env] },
        '#withEnvMixin':: d.fn(help='"A list of environment variable definitions to be used when\\nrunning a step.\\n\\nThe elements are of the form \\"KEY=VALUE\\" for the environment variable\\n\\"KEY\\" being given the value \\"VALUE\\"."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
        withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
        '#withId':: d.fn(help="\"Unique identifier for this build step, used in 'wait_for' to\\nreference this build step as a dependency.\"", args=[d.arg(name='id', type=d.T.string)]),
        withId(id): { id: id },
        '#withName':: d.fn(help="\"The name of the container image that will run this particular build step.\\n\\nIf the image is available in the host's Docker daemon's cache, it will be\\nrun directly. If not, the host will attempt to pull the image first, using\\nthe builder service account's credentials if necessary.\\n\\nThe Docker daemon's cache will already have the latest versions of all of\\nthe officially supported build steps (see https://github.com/GoogleCloudPlatform/cloud-builders \\nfor images and examples).\\nThe Docker daemon will also have cached many of the layers for some popular\\nimages, like \\\"ubuntu\\\", \\\"debian\\\", but they will be refreshed at the time\\nyou attempt to use them.\\n\\nIf you built an image in a previous build step, it will be stored in the\\nhost's Docker daemon's cache and is available to use as the name for a\\nlater build step.\"", args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withSecretEnv':: d.fn(help="\"A list of environment variables which are encrypted using\\na Cloud Key\\nManagement Service crypto key. These values must be specified in\\nthe build's 'Secret'.\"", args=[d.arg(name='secretEnv', type=d.T.array)]),
        withSecretEnv(secretEnv): { secretEnv: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] },
        '#withSecretEnvMixin':: d.fn(help="\"A list of environment variables which are encrypted using\\na Cloud Key\\nManagement Service crypto key. These values must be specified in\\nthe build's 'Secret'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='secretEnv', type=d.T.array)]),
        withSecretEnvMixin(secretEnv): { secretEnv+: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] },
        '#withTimeout':: d.fn(help='"Time limit for executing this build step. If not defined,\\nthe step has no\\ntime limit and will be allowed to continue to run until either it\\ncompletes or the build itself times out."', args=[d.arg(name='timeout', type=d.T.string)]),
        withTimeout(timeout): { timeout: timeout },
        '#withTiming':: d.fn(help='"Output only. Stores timing information for executing this\\nbuild step."', args=[d.arg(name='timing', type=d.T.string)]),
        withTiming(timing): { timing: timing },
        '#withVolumes':: d.fn(help='"List of volumes to mount into the build step.\\n\\nEach volume is created as an empty volume prior to execution of the\\nbuild step. Upon completion of the build, volumes and their contents\\nare discarded.\\n\\nUsing a named volume in only one step is not valid as it is\\nindicative of a build request with an incorrect configuration."', args=[d.arg(name='volumes', type=d.T.array)]),
        withVolumes(volumes): { volumes: if std.isArray(v=volumes) then volumes else [volumes] },
        '#withVolumesMixin':: d.fn(help='"List of volumes to mount into the build step.\\n\\nEach volume is created as an empty volume prior to execution of the\\nbuild step. Upon completion of the build, volumes and their contents\\nare discarded.\\n\\nUsing a named volume in only one step is not valid as it is\\nindicative of a build request with an incorrect configuration."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
        withVolumesMixin(volumes): { volumes+: if std.isArray(v=volumes) then volumes else [volumes] },
        '#withWaitFor':: d.fn(help="\"The ID(s) of the step(s) that this build step depends on.\\n\\nThis build step will not start until all the build steps in 'wait_for'\\nhave completed successfully. If 'wait_for' is empty, this build step\\nwill start when all previous build steps in the 'Build.Steps' list\\nhave completed successfully.\"", args=[d.arg(name='waitFor', type=d.T.array)]),
        withWaitFor(waitFor): { waitFor: if std.isArray(v=waitFor) then waitFor else [waitFor] },
        '#withWaitForMixin':: d.fn(help="\"The ID(s) of the step(s) that this build step depends on.\\n\\nThis build step will not start until all the build steps in 'wait_for'\\nhave completed successfully. If 'wait_for' is empty, this build step\\nwill start when all previous build steps in the 'Build.Steps' list\\nhave completed successfully.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='waitFor', type=d.T.array)]),
        withWaitForMixin(waitFor): { waitFor+: if std.isArray(v=waitFor) then waitFor else [waitFor] },
      },
      '#withImages':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps.\\nThe images are pushed using the builder service account's credentials.\\nThe digests of the pushed images will be stored in the Build resource's results field.\\nIf any of the images fail to be pushed, the build status is marked FAILURE.\"", args=[d.arg(name='images', type=d.T.array)]),
      withImages(images): { spec+: { build+: { images: if std.isArray(v=images) then images else [images] } } },
      '#withImagesMixin':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps.\\nThe images are pushed using the builder service account's credentials.\\nThe digests of the pushed images will be stored in the Build resource's results field.\\nIf any of the images fail to be pushed, the build status is marked FAILURE.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='images', type=d.T.array)]),
      withImagesMixin(images): { spec+: { build+: { images+: if std.isArray(v=images) then images else [images] } } },
      '#withQueueTtl':: d.fn(help="\"TTL in queue for this build. If provided and the build is enqueued longer than this value, \\nthe build will expire and the build status will be EXPIRED.\\nThe TTL starts ticking from createTime.\\nA duration in seconds with up to nine fractional digits, terminated by 's'. Example: \\\"3.5s\\\".\"", args=[d.arg(name='queueTtl', type=d.T.string)]),
      withQueueTtl(queueTtl): { spec+: { build+: { queueTtl: queueTtl } } },
      '#withSecret':: d.fn(help='"Secrets to decrypt using Cloud Key Management Service."', args=[d.arg(name='secret', type=d.T.array)]),
      withSecret(secret): { spec+: { build+: { secret: if std.isArray(v=secret) then secret else [secret] } } },
      '#withSecretMixin':: d.fn(help='"Secrets to decrypt using Cloud Key Management Service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secret', type=d.T.array)]),
      withSecretMixin(secret): { spec+: { build+: { secret+: if std.isArray(v=secret) then secret else [secret] } } },
      '#withStep':: d.fn(help='"The operations to be performed on the workspace."', args=[d.arg(name='step', type=d.T.array)]),
      withStep(step): { spec+: { build+: { step: if std.isArray(v=step) then step else [step] } } },
      '#withStepMixin':: d.fn(help='"The operations to be performed on the workspace."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='step', type=d.T.array)]),
      withStepMixin(step): { spec+: { build+: { step+: if std.isArray(v=step) then step else [step] } } },
      '#withSubstitutions':: d.fn(help='"Substitutions data for Build resource."', args=[d.arg(name='substitutions', type=d.T.object)]),
      withSubstitutions(substitutions): { spec+: { build+: { substitutions: substitutions } } },
      '#withSubstitutionsMixin':: d.fn(help='"Substitutions data for Build resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='substitutions', type=d.T.object)]),
      withSubstitutionsMixin(substitutions): { spec+: { build+: { substitutions+: substitutions } } },
      '#withTags':: d.fn(help='"Tags for annotation of a Build. These are not docker tags."', args=[d.arg(name='tags', type=d.T.array)]),
      withTags(tags): { spec+: { build+: { tags: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTagsMixin':: d.fn(help='"Tags for annotation of a Build. These are not docker tags."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.array)]),
      withTagsMixin(tags): { spec+: { build+: { tags+: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTimeout':: d.fn(help='"Amount of time that this build should be allowed to run, to second granularity.\\nIf this amount of time elapses, work on the build will cease and the build status will be TIMEOUT.\\nThis timeout must be equal to or greater than the sum of the timeouts for build steps within the build.\\nThe expected format is the number of seconds followed by s.\\nDefault time is ten minutes (600s)."', args=[d.arg(name='timeout', type=d.T.string)]),
      withTimeout(timeout): { spec+: { build+: { timeout: timeout } } },
    },
    '#gitFileSource':: d.obj(help='"The file source describing the local or remote Build template."'),
    gitFileSource: {
      '#withPath':: d.fn(help='"The path of the file, with the repo root as the root of the path."', args=[d.arg(name='path', type=d.T.string)]),
      withPath(path): { spec+: { gitFileSource+: { path: path } } },
      '#withRepoType':: d.fn(help='"The type of the repo, since it may not be explicit from the repo field (e.g from a URL). Possible values: [\\"UNKNOWN\\", \\"CLOUD_SOURCE_REPOSITORIES\\", \\"GITHUB\\"]."', args=[d.arg(name='repoType', type=d.T.string)]),
      withRepoType(repoType): { spec+: { gitFileSource+: { repoType: repoType } } },
      '#withRevision':: d.fn(help='"The branch, tag, arbitrary ref, or SHA version of the repo to use when resolving the \\nfilename (optional). This field respects the same syntax/resolution as described here: https://git-scm.com/docs/gitrevisions \\nIf unspecified, the revision from which the trigger invocation originated is assumed to be the revision from which to read the specified path."', args=[d.arg(name='revision', type=d.T.string)]),
      withRevision(revision): { spec+: { gitFileSource+: { revision: revision } } },
      '#withUri':: d.fn(help='"The URI of the repo (optional). If unspecified, the repo from which the trigger \\ninvocation originated is assumed to be the repo from which to read the specified path."', args=[d.arg(name='uri', type=d.T.string)]),
      withUri(uri): { spec+: { gitFileSource+: { uri: uri } } },
    },
    '#github':: d.obj(help="\"Describes the configuration of a trigger that creates a build whenever a GitHub event is received.\\n\\nOne of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\""),
    github: {
      '#pullRequest':: d.obj(help="\"filter to match changes in pull requests. Specify only one of 'pull_request' or 'push'.\""),
      pullRequest: {
        '#withBranch':: d.fn(help='"Regex of branches to match."', args=[d.arg(name='branch', type=d.T.string)]),
        withBranch(branch): { spec+: { github+: { pullRequest+: { branch: branch } } } },
        '#withCommentControl':: d.fn(help='"Whether to block builds on a \\"/gcbrun\\" comment from a repository owner or collaborator. Possible values: [\\"COMMENTS_DISABLED\\", \\"COMMENTS_ENABLED\\", \\"COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY\\"]."', args=[d.arg(name='commentControl', type=d.T.string)]),
        withCommentControl(commentControl): { spec+: { github+: { pullRequest+: { commentControl: commentControl } } } },
        '#withInvertRegex':: d.fn(help='"If true, branches that do NOT match the git_ref will trigger a build."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
        withInvertRegex(invertRegex): { spec+: { github+: { pullRequest+: { invertRegex: invertRegex } } } },
      },
      '#push':: d.obj(help="\"filter to match changes in refs, like branches or tags. Specify only one of 'pull_request' or 'push'.\""),
      push: {
        '#withBranch':: d.fn(help='"Regex of branches to match.  Specify only one of branch or tag."', args=[d.arg(name='branch', type=d.T.string)]),
        withBranch(branch): { spec+: { github+: { push+: { branch: branch } } } },
        '#withInvertRegex':: d.fn(help='"When true, only trigger a build if the revision regex does NOT match the git_ref regex."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
        withInvertRegex(invertRegex): { spec+: { github+: { push+: { invertRegex: invertRegex } } } },
        '#withTag':: d.fn(help='"Regex of tags to match.  Specify only one of branch or tag."', args=[d.arg(name='tag', type=d.T.string)]),
        withTag(tag): { spec+: { github+: { push+: { tag: tag } } } },
      },
      '#withName':: d.fn(help='"Name of the repository. For example: The name for\\nhttps://github.com/googlecloudplatform/cloud-builders is \\"cloud-builders\\"."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { github+: { name: name } } },
      '#withOwner':: d.fn(help='"Owner of the repository. For example: The owner for\\nhttps://github.com/googlecloudplatform/cloud-builders is \\"googlecloudplatform\\"."', args=[d.arg(name='owner', type=d.T.string)]),
      withOwner(owner): { spec+: { github+: { owner: owner } } },
    },
    '#pubsubConfig':: d.obj(help="\"PubsubConfig describes the configuration of a trigger that creates \\na build whenever a Pub/Sub message is published.\\n\\nOne of 'trigger_template', 'github', 'pubsub_config' 'webhook_config' or 'source_to_build' must be provided.\""),
    pubsubConfig: {
      '#serviceAccountRef':: d.obj(help='"Service account that will make the push request."'),
      serviceAccountRef: {
        '#withExternal':: d.fn(help='"Allowed value: The `email` field of an `IAMServiceAccount` resource."', args=[d.arg(name='external', type=d.T.string)]),
        withExternal(external): { spec+: { pubsubConfig+: { serviceAccountRef+: { external: external } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { pubsubConfig+: { serviceAccountRef+: { name: name } } } },
        '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { pubsubConfig+: { serviceAccountRef+: { namespace: namespace } } } },
      },
      '#topicRef':: d.obj(help='"The name of the topic from which this subscription\\nis receiving messages."'),
      topicRef: {
        '#withExternal':: d.fn(help='"Allowed value: string of the format `projects/{{project}}/topics/{{value}}`, where {{value}} is the `name` field of a `PubSubTopic` resource."', args=[d.arg(name='external', type=d.T.string)]),
        withExternal(external): { spec+: { pubsubConfig+: { topicRef+: { external: external } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { pubsubConfig+: { topicRef+: { name: name } } } },
        '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { pubsubConfig+: { topicRef+: { namespace: namespace } } } },
      },
      '#withState':: d.fn(help='"Potential issues with the underlying Pub/Sub subscription configuration.\\nOnly populated on get requests."', args=[d.arg(name='state', type=d.T.string)]),
      withState(state): { spec+: { pubsubConfig+: { state: state } } },
      '#withSubscription':: d.fn(help='"Output only. Name of the subscription."', args=[d.arg(name='subscription', type=d.T.string)]),
      withSubscription(subscription): { spec+: { pubsubConfig+: { subscription: subscription } } },
    },
    '#serviceAccountRef':: d.obj(help='"The service account used for all user-controlled operations including\\ntriggers.patch, triggers.run, builds.create, and builds.cancel.\\n\\nIf no service account is set, then the standard Cloud Build service account\\n([PROJECT_NUM]@system.gserviceaccount.com) will be used instead.\\n\\nWhen populating via the external field, the following format is supported:\\nprojects/{PROJECT_ID}/serviceAccounts/{SERVICE_ACCOUNT_EMAIL}"'),
    serviceAccountRef: {
      '#withExternal':: d.fn(help='"Allowed value: string of the format `projects/{{project}}/serviceAccounts/{{value}}`, where {{value}} is the `email` field of an `IAMServiceAccount` resource."', args=[d.arg(name='external', type=d.T.string)]),
      withExternal(external): { spec+: { serviceAccountRef+: { external: external } } },
      '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { serviceAccountRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { serviceAccountRef+: { namespace: namespace } } },
    },
    '#sourceToBuild':: d.obj(help="\"The repo and ref of the repository from which to build. \\nThis field is used only for those triggers that do not respond to SCM events. \\nTriggers that respond to such events build source at whatever commit caused the event. \\nThis field is currently only used by Webhook, Pub/Sub, Manual, and Cron triggers.\\n\\nOne of 'trigger_template', 'github', 'pubsub_config' 'webhook_config' or 'source_to_build' must be provided.\""),
    sourceToBuild: {
      '#withRef':: d.fn(help='"The branch or tag to use. Must start with \\"refs/\\" (required)."', args=[d.arg(name='ref', type=d.T.string)]),
      withRef(ref): { spec+: { sourceToBuild+: { ref: ref } } },
      '#withRepoType':: d.fn(help='"The type of the repo, since it may not be explicit from the repo field (e.g from a URL). Possible values: [\\"UNKNOWN\\", \\"CLOUD_SOURCE_REPOSITORIES\\", \\"GITHUB\\"]."', args=[d.arg(name='repoType', type=d.T.string)]),
      withRepoType(repoType): { spec+: { sourceToBuild+: { repoType: repoType } } },
      '#withUri':: d.fn(help='"The URI of the repo (required)."', args=[d.arg(name='uri', type=d.T.string)]),
      withUri(uri): { spec+: { sourceToBuild+: { uri: uri } } },
    },
    '#triggerTemplate':: d.obj(help="\"Template describing the types of source changes to trigger a build.\\n\\nBranch and tag names in trigger templates are interpreted as regular\\nexpressions. Any branch or tag change that matches that regular\\nexpression will trigger a build.\\n\\nOne of 'trigger_template', 'github', 'pubsub_config', 'webhook_config' or 'source_to_build' must be provided.\""),
    triggerTemplate: {
      '#repoRef':: d.obj(help='"The Cloud Source Repository to build. If omitted, the repo with\\nname \\"default\\" is assumed."'),
      repoRef: {
        '#withExternal':: d.fn(help='"Allowed value: The `name` field of a `SourceRepoRepository` resource."', args=[d.arg(name='external', type=d.T.string)]),
        withExternal(external): { spec+: { triggerTemplate+: { repoRef+: { external: external } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { triggerTemplate+: { repoRef+: { name: name } } } },
        '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { triggerTemplate+: { repoRef+: { namespace: namespace } } } },
      },
      '#withBranchName':: d.fn(help='"Name of the branch to build. Exactly one a of branch name, tag, or commit SHA must be provided.\\nThis field is a regular expression."', args=[d.arg(name='branchName', type=d.T.string)]),
      withBranchName(branchName): { spec+: { triggerTemplate+: { branchName: branchName } } },
      '#withCommitSha':: d.fn(help='"Explicit commit SHA to build. Exactly one of a branch name, tag, or commit SHA must be provided."', args=[d.arg(name='commitSha', type=d.T.string)]),
      withCommitSha(commitSha): { spec+: { triggerTemplate+: { commitSha: commitSha } } },
      '#withDir':: d.fn(help="\"Directory, relative to the source root, in which to run the build.\\n\\nThis must be a relative path. If a step's dir is specified and\\nis an absolute path, this value is ignored for that step's\\nexecution.\"", args=[d.arg(name='dir', type=d.T.string)]),
      withDir(dir): { spec+: { triggerTemplate+: { dir: dir } } },
      '#withInvertRegex':: d.fn(help='"Only trigger a build if the revision regex does NOT match the revision regex."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
      withInvertRegex(invertRegex): { spec+: { triggerTemplate+: { invertRegex: invertRegex } } },
      '#withTagName':: d.fn(help='"Name of the tag to build. Exactly one of a branch name, tag, or commit SHA must be provided.\\nThis field is a regular expression."', args=[d.arg(name='tagName', type=d.T.string)]),
      withTagName(tagName): { spec+: { triggerTemplate+: { tagName: tagName } } },
    },
    '#webhookConfig':: d.obj(help="\"WebhookConfig describes the configuration of a trigger that creates \\na build whenever a webhook is sent to a trigger's webhook URL.\\n\\nOne of 'trigger_template', 'github', 'pubsub_config' 'webhook_config' or 'source_to_build' must be provided.\""),
    webhookConfig: {
      '#secretRef':: d.obj(help='"The secret required"'),
      secretRef: {
        '#withExternal':: d.fn(help='"Allowed value: The `name` field of a `SecretManagerSecret` resource."', args=[d.arg(name='external', type=d.T.string)]),
        withExternal(external): { spec+: { webhookConfig+: { secretRef+: { external: external } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { webhookConfig+: { secretRef+: { name: name } } } },
        '#withNamespace':: d.fn(help='"Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { webhookConfig+: { secretRef+: { namespace: namespace } } } },
      },
      '#withState':: d.fn(help='"Potential issues with the underlying Pub/Sub subscription configuration.\\nOnly populated on get requests."', args=[d.arg(name='state', type=d.T.string)]),
      withState(state): { spec+: { webhookConfig+: { state: state } } },
    },
    '#withDescription':: d.fn(help='"Human-readable description of the trigger."', args=[d.arg(name='description', type=d.T.string)]),
    withDescription(description): { spec+: { description: description } },
    '#withDisabled':: d.fn(help='"Whether the trigger is disabled or not. If true, the trigger will never result in a build."', args=[d.arg(name='disabled', type=d.T.boolean)]),
    withDisabled(disabled): { spec+: { disabled: disabled } },
    '#withFilename':: d.fn(help='"Path, from the source root, to a file whose contents is used for the template. \\nEither a filename or build template must be provided. Set this only when using trigger_template or github.\\nWhen using Pub/Sub, Webhook or Manual set the file name using git_file_source instead."', args=[d.arg(name='filename', type=d.T.string)]),
    withFilename(filename): { spec+: { filename: filename } },
    '#withFilter':: d.fn(help='"A Common Expression Language string. Used only with Pub/Sub and Webhook."', args=[d.arg(name='filter', type=d.T.string)]),
    withFilter(filter): { spec+: { filter: filter } },
    '#withIgnoredFiles':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match\\nextended with support for '**'.\\n\\nIf ignoredFiles and changed files are both empty, then they are not\\nused to determine whether or not to trigger a build.\\n\\nIf ignoredFiles is not empty, then we ignore any files that match any\\nof the ignored_file globs. If the change has no files that are outside\\nof the ignoredFiles globs, then we do not trigger a build.\"", args=[d.arg(name='ignoredFiles', type=d.T.array)]),
    withIgnoredFiles(ignoredFiles): { spec+: { ignoredFiles: if std.isArray(v=ignoredFiles) then ignoredFiles else [ignoredFiles] } },
    '#withIgnoredFilesMixin':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match\\nextended with support for '**'.\\n\\nIf ignoredFiles and changed files are both empty, then they are not\\nused to determine whether or not to trigger a build.\\n\\nIf ignoredFiles is not empty, then we ignore any files that match any\\nof the ignored_file globs. If the change has no files that are outside\\nof the ignoredFiles globs, then we do not trigger a build.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='ignoredFiles', type=d.T.array)]),
    withIgnoredFilesMixin(ignoredFiles): { spec+: { ignoredFiles+: if std.isArray(v=ignoredFiles) then ignoredFiles else [ignoredFiles] } },
    '#withIncludedFiles':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match\\nextended with support for '**'.\\n\\nIf any of the files altered in the commit pass the ignoredFiles filter\\nand includedFiles is empty, then as far as this filter is concerned, we\\nshould trigger the build.\\n\\nIf any of the files altered in the commit pass the ignoredFiles filter\\nand includedFiles is not empty, then we make sure that at least one of\\nthose files matches a includedFiles glob. If not, then we do not trigger\\na build.\"", args=[d.arg(name='includedFiles', type=d.T.array)]),
    withIncludedFiles(includedFiles): { spec+: { includedFiles: if std.isArray(v=includedFiles) then includedFiles else [includedFiles] } },
    '#withIncludedFilesMixin':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match\\nextended with support for '**'.\\n\\nIf any of the files altered in the commit pass the ignoredFiles filter\\nand includedFiles is empty, then as far as this filter is concerned, we\\nshould trigger the build.\\n\\nIf any of the files altered in the commit pass the ignoredFiles filter\\nand includedFiles is not empty, then we make sure that at least one of\\nthose files matches a includedFiles glob. If not, then we do not trigger\\na build.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='includedFiles', type=d.T.array)]),
    withIncludedFilesMixin(includedFiles): { spec+: { includedFiles+: if std.isArray(v=includedFiles) then includedFiles else [includedFiles] } },
    '#withSubstitutions':: d.fn(help='"Substitutions data for Build resource."', args=[d.arg(name='substitutions', type=d.T.object)]),
    withSubstitutions(substitutions): { spec+: { substitutions: substitutions } },
    '#withSubstitutionsMixin':: d.fn(help='"Substitutions data for Build resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='substitutions', type=d.T.object)]),
    withSubstitutionsMixin(substitutions): { spec+: { substitutions+: substitutions } },
    '#withTags':: d.fn(help='"Tags for annotation of a BuildTrigger."', args=[d.arg(name='tags', type=d.T.array)]),
    withTags(tags): { spec+: { tags: if std.isArray(v=tags) then tags else [tags] } },
    '#withTagsMixin':: d.fn(help='"Tags for annotation of a BuildTrigger."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.array)]),
    withTagsMixin(tags): { spec+: { tags+: if std.isArray(v=tags) then tags else [tags] } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
